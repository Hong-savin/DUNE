{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI2\n",
    "updates\n",
    "1. pick labels\n",
    "2. change prob acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick the labels that you want to use here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_labels = [\"door_nock\",\"glass_shatter\",\"car_horn\",\"dog_bark\",\"drilling\",\"nothing\",\"siren\",\"nothing2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sound_rate (only raspberrypi use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = '''pcm.!default {\n",
    "#     type asym\n",
    "#     capture.pcm \"mic\"\n",
    "#     playback.pcm \"speaker\"\n",
    "# }\n",
    "# pcm.mic {\n",
    "#     type plug\n",
    "#     slave {\n",
    "#         pcm \"hw:2,0\"\n",
    "#     }\n",
    "# }\n",
    "# pcm.speaker {\n",
    "#     type plug\n",
    "#     slave {\n",
    "#         pcm \"hw:1,0\"\n",
    "#     }\n",
    "# }'''\n",
    "\n",
    "# # 파일 경로와 이름 설정\n",
    "# file_path = \"/home/pi/.asoundrc\"\n",
    "\n",
    "# # 텍스트 파일 생성 및 저장\n",
    "# with open(file_path, \"w\") as file:\n",
    "#     file.write(text)\n",
    "\n",
    "# print(\"Text saved to:\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 경로: /Volumes/새 볼륨/GARAGE/@DUNE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "print(\"현재 경로:\", current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to the model: /Volumes/새 볼륨/GARAGE/@DUNE/../@AI/Sound Classification/ResNet18_02.pth\n"
     ]
    }
   ],
   "source": [
    "# Relative path to the model file\n",
    "relative_path_to_model = \"../@AI/Sound Classification/ResNet18_02.pth\"\n",
    "\n",
    "# Combine the current path and the relative path to create the absolute path to the model\n",
    "path_to_model = os.path.join(current_path, relative_path_to_model)\n",
    "\n",
    "print(\"Path to the model:\", path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load the model. Please check the model file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owo/anaconda3/envs/torchenv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/owo/anaconda3/envs/torchenv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#One GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(512, len(selected_labels))\n",
    "try:\n",
    "    state_dict = torch.load(path_to_model, map_location=device)\n",
    "    new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    print(\"Model successfully loaded deivce : \",device)\n",
    "except:\n",
    "    print(\"Failed to load the model. Please check the model file.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owo/anaconda3/envs/torchenv/lib/python3.11/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from torchvision import transforms  # Import the transforms module\n",
    "\n",
    "\n",
    "#Transform\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "class MonoToColor(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(MonoToColor, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.repeat(self.num_channels, 1, 1)\n",
    "\n",
    "# Apply the same transformation as used during training\n",
    "transformation = transforms.Compose([\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=128),\n",
    "    torchaudio.transforms.AmplitudeToDB(stype='power', top_db=80),\n",
    "    MonoToColor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech to text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import speech_recognition as sr\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read audio func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio():\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=pyaudio.paInt16, channels=1, rate=16000, frames_per_buffer=1024, input=True)\n",
    "    frames = []\n",
    "    for i in range(0, int(16000 / 1024 * 3)):\n",
    "        data = stream.read(1024)\n",
    "        frames.append(data)\n",
    "    stream.close()\n",
    "    audio.terminate()  # close the PyAudio object\n",
    "    return b''.join(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio_data = sr.AudioData(audio, 16000, 2)\n",
    "    try:\n",
    "        text = recognizer.recognize_sphinx(audio_data)\n",
    "        \n",
    "        return text\n",
    "    except:\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spinx Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(times):\n",
    "    for i in range(0, times):\n",
    "        audio = record_audio()\n",
    "        text = transcribe_audio(audio)\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMES = 0\n",
    "if __name__ == \"__main__\":\n",
    "    main(TIMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOUND EFFECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cpu\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "import sounddevice as sd\n",
    "\n",
    "print(\"device : \",device)\n",
    "## print every labels\n",
    "def continuous_sound_prediction(model, device, transformation, sample_rate, target_sample_rate):\n",
    "    # Define class labels\n",
    "\n",
    "    # Record a 2 seconds mono audio at the specified sample rate\n",
    "    duration = 2.0  # seconds\n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1) \n",
    "    sd.wait()\n",
    "\n",
    "    # Convert to PyTorch tensor and switch channels and frames\n",
    "    recording = torch.from_numpy(recording).float()\n",
    "    recording = torch.transpose(recording, 0, 1)\n",
    "\n",
    "    # Resample if necessary\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(sample_rate, target_sample_rate)\n",
    "        recording = resampler(recording)\n",
    "\n",
    "    # Mix down if necessary\n",
    "    if recording.shape[0] > 1:\n",
    "        recording = torch.mean(recording, dim=0, keepdim=True)\n",
    "\n",
    "    # Cut or pad if necessary\n",
    "    if recording.shape[1] > target_sample_rate:\n",
    "        recording = recording[:, :target_sample_rate]\n",
    "    elif recording.shape[1] < target_sample_rate:\n",
    "        num_missing_samples = target_sample_rate - recording.shape[1]\n",
    "        last_dim_padding = (0, num_missing_samples)\n",
    "        recording = nn.functional.pad(recording, last_dim_padding)\n",
    "\n",
    "    # Apply transformation\n",
    "    recording = transformation(recording)\n",
    "\n",
    "    # Make the prediction\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():  # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "        recording = recording.to(device)\n",
    "        outputs = model(recording[None, ...])\n",
    "        #probabilities = F.softmax(outputs, dim=1)  # apply softmax to output (for 100%)\n",
    "        #_, predicted = torch.max(outputs, 1)\n",
    "        probabilities = torch.sigmoid(outputs)  # apply sigmoid to output (for indivisual points)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Get predicted label and its corresponding probability\n",
    "    predicted_label = selected_labels[predicted.item()]\n",
    "    predicted_confidence = probabilities[0, predicted.item()].item()  # get the probability of the predicted class\n",
    "\n",
    "    ######## Adjust 'x' probability   #########\n",
    "    change_label = \"glass_shatter\"\n",
    "    change_probability = 0.5\n",
    "    try:# if you have something to reduce\n",
    "        x_index = selected_labels.index(change_label)\n",
    "        probabilities[0, x_index] = max(0.0, probabilities[0, x_index].item() - change_probability)\n",
    "    except:#if you dont\n",
    "        pass\n",
    "    # Print the probabilities of all labels in one line\n",
    "    #prob_strs = [f\"{label} {probabilities[0, idx].item():.2%}\" for idx, label in enumerate(selected_labels)]\n",
    "    #print(f\"/ \".join(prob_strs))\n",
    "\n",
    "    if predicted_confidence > 0.0:\n",
    "        return predicted_label, predicted_confidence, probabilities\n",
    "    else:\n",
    "        return \"NONE\" , 0 , \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 결과 값 : \n",
      "RPi.GPIO import failed. No vibration\n",
      "pass vibration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.fonts: Populating font family aliases took 88 ms. Replace uses of missing font family \"AppleSystemUIFont\" with one that exists to avoid this cost. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the tunnel\n",
      "all worrying job too\n",
      "all the aging fond family\n",
      "and the sections messina\n",
      "mendocino\n",
      "it didn't image\n",
      "so\n",
      "english image you lives here\n",
      "english the money\n",
      "call today\n",
      "all the tunnels\n",
      "aw\n",
      "it alone\n",
      "most alone\n",
      "this is known is a killer\n",
      "those are to a total\n",
      "those who want to go\n",
      "up\n"
     ]
    }
   ],
   "source": [
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from PyQt5.QtCore import QThread, pyqtSignal\n",
    "from PyQt5.QtGui import QMovie\n",
    "\n",
    "from time import sleep\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyaudio\n",
    "import torchaudio\n",
    "import sounddevice as sd\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "###### INIT ######\n",
    "p = pyaudio.PyAudio()\n",
    "sample_rate = SAMPLE_RATE\n",
    "target_sample_rate = SAMPLE_RATE\n",
    "mode = 0\n",
    "print(\" 결과 값 : \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sound Analysis class running on a separate thread\n",
    "class SoundAnalysis(QThread):\n",
    "    # Define a pyqtSignal with str type, which will be used to send the analysis results to the main thread\n",
    "    result_signal = pyqtSignal(str, float)  # Add a float type for the probability\n",
    "\n",
    "    def __init__(self, model, device, transformation, sample_rate):\n",
    "        QThread.__init__(self)\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.transformation = transformation\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "\n",
    "    def run(self):## Main code\n",
    "        count = 0\n",
    "        text_str = \"\"\n",
    "        while True:\n",
    "\n",
    "            if mode == True:\n",
    "                text_str = \"\" #empty the text strings\n",
    "\n",
    "                predicted_label, predicted_confidence, probabilities = continuous_sound_prediction(model, device, transformation, SAMPLE_RATE, SAMPLE_RATE) \n",
    "                if mode == True:\n",
    "                    try:               \n",
    "                        self.result_signal.emit(predicted_label, predicted_confidence)\n",
    "                        prob_strs = [f\"{label} {probabilities[0, idx].item():.2%}\" for idx, label in enumerate(selected_labels)]\n",
    "                        #vibration()\n",
    "                        print(f\"\\r{count} / \" + \" / \".join(prob_strs), end=\"\")\n",
    "                    except:\n",
    "                        self.result_signal.emit(predicted_label, predicted_confidence)\n",
    "                    count = count + 1\n",
    "            if mode == False:\n",
    "\n",
    "                times = 2\n",
    "                for _ in range(0, times):\n",
    "                    audio = record_audio()\n",
    "                    text = transcribe_audio(audio)\n",
    "                    print(text)\n",
    "                    text_str += text + \" \"\n",
    "                    if mode == True: ## This is checking again if the button is pushed. If I dont add this, it will reset_label and show the text_str again before going to mode True\n",
    "                        break\n",
    "                    self.result_signal.emit(text_str,0)\n",
    "        \n",
    "    def reset_label(self):# Restting the labels when the button is pressed\n",
    "        self.result_signal.emit(\"켜는중\", 0)\n",
    "class Ui_MainWindow(object):\n",
    "    def setupUi(self, MainWindow):\n",
    "        MainWindow.setObjectName(\"MainWindow\")\n",
    "        MainWindow.resize(640, 480)\n",
    "        self.received_text = \"\"\n",
    "        self.centralwidget = QtWidgets.QWidget(MainWindow)\n",
    "        self.centralwidget.setObjectName(\"centralwidget\")\n",
    "        \n",
    "        # Create a QScrollArea\n",
    "        self.scrollArea = QtWidgets.QScrollArea(self.centralwidget)\n",
    "        self.scrollArea.setGeometry(QtCore.QRect(40, 300, 561, 91))\n",
    "        self.scrollArea.setWidgetResizable(True)\n",
    "        self.scrollArea.setObjectName(\"scrollArea\")\n",
    "\n",
    "        # Create the label inside the QScrollArea\n",
    "        self.label = QtWidgets.QLabel(self.scrollArea)\n",
    "        self.label.setAlignment(QtCore.Qt.AlignTop)\n",
    "        self.label.setObjectName(\"text_label\")\n",
    "        self.label.setWordWrap(True)\n",
    "        self.scrollArea.setWidget(self.label)\n",
    "\n",
    "        self.label_2 = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.label_2.setGeometry(QtCore.QRect(40, 30, 381, 211))\n",
    "        self.label_2.setText(\"\")\n",
    "        self.label_2.setObjectName(\"imgae_image\")\n",
    "\n",
    "        self.pushButton = QtWidgets.QPushButton(self.centralwidget)\n",
    "        self.pushButton.setGeometry(QtCore.QRect(470, 40, 141, 101))\n",
    "        self.pushButton.setObjectName(\"pushButton\")\n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "\n",
    "        #english_text_label\n",
    "        self.new_label = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.new_label.setGeometry(QtCore.QRect(40, 200, 561, 201))\n",
    "        self.new_label.setText(\"\")\n",
    "        self.new_label.setAlignment(QtCore.Qt.AlignCenter)  # 텍스트 중앙 정렬\n",
    "        self.new_label.setObjectName(\"english_text_label\")\n",
    "        self.new_label.hide()  # Hide the new label initially\n",
    "        #english_image_label\n",
    "        self.new_label_2 = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.new_label_2.setGeometry(QtCore.QRect(50, 40, 144, 130))\n",
    "        self.new_label_2.setPixmap(QtGui.QPixmap(\"english_image.png\"))\n",
    "        self.new_label_2.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.new_label_2.setObjectName(\"english_image_label\")\n",
    "        self.new_label_2.hide()  # Hide the new label initially\n",
    "\n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "        self.menubar = QtWidgets.QMenuBar(MainWindow)\n",
    "        self.menubar.setGeometry(QtCore.QRect(0, 0, 800, 29))\n",
    "        self.menubar.setObjectName(\"menubar\")\n",
    "        MainWindow.setMenuBar(self.menubar)\n",
    "        self.statusbar = QtWidgets.QStatusBar(MainWindow)\n",
    "        self.statusbar.setObjectName(\"statusbar\")\n",
    "        MainWindow.setStatusBar(self.statusbar)\n",
    "\n",
    "        self.retranslateUi(MainWindow)\n",
    "        QtCore.QMetaObject.connectSlotsByName(MainWindow)\n",
    "\n",
    "        self.pushButton.clicked.connect(self.onPushButtonClicked)\n",
    "\n",
    "        # Initialize SoundAnalysis and connect the result_signal with the updateLabel function\n",
    "        self.sound_analysis = SoundAnalysis(model, device, transformation, SAMPLE_RATE)\n",
    "        self.sound_analysis.result_signal.connect(self.updateLabel)\n",
    "        self.sound_analysis.result_signal.connect(self.updateLabel2)\n",
    "        self.sound_analysis.start()  # Start the sound analysis thread\n",
    "        \n",
    "        self.is_new_labels_visible = False\n",
    "        \n",
    "\n",
    "    def onPushButtonClicked(self): ######BUTTON#######\n",
    "        global mode\n",
    "        mode = not mode\n",
    "        self.sound_analysis.reset_label()#reset the screen (its connected to the sound analysis class)\n",
    "        print(\"mode now :  \",mode)\n",
    "\n",
    "    def updateLabel(self, predicted_label, predicted_confidence):\n",
    "        #print(\"Received signal\")  # Print message when signal is received\n",
    "        if predicted_confidence == 0:\n",
    "            self.label.setText(f\"{predicted_label}\")\n",
    "        else:\n",
    "            self.label.setText(f\"{predicted_label}  {predicted_confidence*100:.2f}%\")\n",
    "        #print(predicted_label)\n",
    "        \n",
    "        # After updating the text, ensure the QScrollArea scrolls to the bottom\n",
    "        self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().maximum())\n",
    "\n",
    "\n",
    "        \n",
    "    def updateLabel2(self, predicted_label):\n",
    "        relative_image_folder_path = \"../png\" #\\ only works for windows\n",
    "        image_folder_path= os.path.join(current_path, relative_image_folder_path)\n",
    "        full_file_name = os.path.join(image_folder_path, f\"{predicted_label}.png\")\n",
    "        #self.movie = QMovie(full_file_name)\n",
    "        #self.label.setMovie(self.movie)\n",
    "        #self.movie.start()\n",
    "        self.label_2.setPixmap(QtGui.QPixmap(full_file_name)) \n",
    "        #print(predicted_label)\n",
    "\n",
    "\n",
    "    def retranslateUi(self, MainWindow):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        MainWindow.setWindowTitle(_translate(\"MainWindow\", \"MainWindow\"))\n",
    "        self.label.setFont(QtGui.QFont(\"AppleSystemUIFont\",20))\n",
    "        self.label.setStyleSheet(\"Color : black\")\n",
    "        self.pushButton.setText(_translate(\"MainWindow\", \"PushButton\"))\n",
    "        \n",
    "try:\n",
    "    import RPi.GPIO as GPIO\n",
    "    print(\"RPi.GPIO loaded successfully\")\n",
    "    import threading\n",
    "    print(\"threading loaded successfully\")\n",
    "\n",
    "    class VibrationController:\n",
    "        def __init__(self):\n",
    "            # 핀 번호 설정\n",
    "            self.red_button_pin = 17\n",
    "            self.yellow_button_pin = 22\n",
    "            self.green_button_pin = 27\n",
    "            self.vibration_motor_pin = 18\n",
    "            \n",
    "            # 진동 세기 초기화\n",
    "            self.vibration_intensity_temp = 100\n",
    "            self.vibration_intensity = 0\n",
    "            \n",
    "            # 이전 스위치 상태 초기화\n",
    "            self.prev_red_button_state = GPIO.HIGH\n",
    "            self.prev_yellow_button_state = GPIO.HIGH\n",
    "            self.prev_green_button_state = GPIO.HIGH\n",
    "            \n",
    "            self.debounce_time = 0.2\n",
    "            \n",
    "            # 진동 상태를 저장하는 변수\n",
    "            self.vibration_on = False\n",
    "            \n",
    "            # GPIO 초기화\n",
    "            GPIO.setmode(GPIO.BCM)\n",
    "            GPIO.setup(self.red_button_pin, GPIO.IN, pull_up_down=GPIO.PUD_UP)\n",
    "            GPIO.setup(self.yellow_button_pin, GPIO.IN, pull_up_down=GPIO.PUD_UP)\n",
    "            GPIO.setup(self.green_button_pin, GPIO.IN, pull_up_down=GPIO.PUD_UP)\n",
    "            GPIO.setup(self.vibration_motor_pin, GPIO.OUT)\n",
    "            \n",
    "            # PWM 설정\n",
    "            self.pwm_frequency = 1000\n",
    "            self.pwm = GPIO.PWM(self.vibration_motor_pin, self.pwm_frequency)\n",
    "            self.pwm.start(self.vibration_intensity)\n",
    "        \n",
    "        def display_vibration_intensity(self):\n",
    "            print(f\"진동 세기: {self.vibration_intensity}\")\n",
    "        \n",
    "        def adjust_vibration_intensity(self, button_pin):\n",
    "            if button_pin == self.red_button_pin:\n",
    "                self.vibration_intensity = self.vibration_intensity_temp\n",
    "            elif button_pin == self.yellow_button_pin:\n",
    "                self.vibration_intensity = max(self.vibration_intensity - 10, 0)\n",
    "            elif button_pin == self.green_button_pin:\n",
    "                self.vibration_intensity = min(self.vibration_intensity + 10, 100)\n",
    "            \n",
    "            self.pwm.ChangeDutyCycle(self.vibration_intensity)\n",
    "            self.display_vibration_intensity()\n",
    "        \n",
    "        def run(self):\n",
    "            try:\n",
    "                while True:\n",
    "                    red_button_state = GPIO.input(self.red_button_pin)\n",
    "                    yellow_button_state = GPIO.input(self.yellow_button_pin)\n",
    "                    green_button_state = GPIO.input(self.green_button_pin)\n",
    "            \n",
    "                    if red_button_state != self.prev_red_button_state:\n",
    "                        time.sleep(self.debounce_time)\n",
    "                        if red_button_state != GPIO.input(self.red_button_pin):\n",
    "                            \n",
    "                            if not self.vibration_on:\n",
    "                                self.vibration_on = True\n",
    "                                self.adjust_vibration_intensity(self.red_button_pin)\n",
    "                            else:\n",
    "                                self.vibration_intensity_temp = self.vibration_intensity\n",
    "                                self.vibration_intensity = 0\n",
    "                                self.pwm.ChangeDutyCycle(self.vibration_intensity)\n",
    "                                self.display_vibration_intensity()\n",
    "                                self.vibration_on = False\n",
    "            \n",
    "                        self.prev_red_button_state = red_button_state\n",
    "            \n",
    "                    if yellow_button_state != self.prev_yellow_button_state:\n",
    "                        time.sleep(self.debounce_time)\n",
    "                        if yellow_button_state != GPIO.input(self.yellow_button_pin):\n",
    "                            self.adjust_vibration_intensity(self.yellow_button_pin)\n",
    "                        self.prev_yellow_button_state = yellow_button_state\n",
    "            \n",
    "                    if green_button_state != self.prev_green_button_state:\n",
    "                        time.sleep(self.debounce_time)\n",
    "                        if green_button_state != GPIO.input(self.green_button_pin):\n",
    "                            self.adjust_vibration_intensity(self.green_button_pin)\n",
    "                        self.prev_green_button_state = green_button_state\n",
    "            \n",
    "                    time.sleep(0.01)  \n",
    "            \n",
    "            except KeyboardInterrupt:\n",
    "                self.pwm.stop()\n",
    "                GPIO.cleanup()\n",
    "except:\n",
    "    print(\"RPi.GPIO import failed. No vibration\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    MainWindow = QtWidgets.QMainWindow()\n",
    "    try:\n",
    "        vibration_controller = VibrationController()\n",
    "        vibration_thread = threading.Thread(target=vibration_controller.run)\n",
    "        vibration_thread.start()\n",
    "    except:\n",
    "        print(\"pass vibration\")\n",
    "    ui = Ui_MainWindow()\n",
    "    ui.setupUi(MainWindow)\n",
    "    MainWindow.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가능한 폰트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtGui import QFontDatabase\n",
    "\n",
    "print(QFontDatabase().families())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
