{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Load the CSV files\n",
    "df_curated = pd.read_csv('train_curated.csv')\n",
    "df_noisy = pd.read_csv('train_noisy.csv')\n",
    "\n",
    "# Paths to the audio files\n",
    "audio_path_curated = '/Users/owo/HOUSE/@DUNE/@AI/Sound Classification2/freesound-audio-tagging-2019/train_curated'\n",
    "audio_path_noisy = '/Users/owo/HOUSE/@DUNE/@AI/Sound Classification2/freesound-audio-tagging-2019/train_noisy'\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df = pd.concat([df_curated, df_noisy], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ae4e.wav</td>\n",
       "      <td>Bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0019ef41.wav</td>\n",
       "      <td>Raindrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ec0ad.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0026c7cb.wav</td>\n",
       "      <td>Run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0026f116.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23149</th>\n",
       "      <td>fffc7128.wav</td>\n",
       "      <td>Accordion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23150</th>\n",
       "      <td>fffcf57b.wav</td>\n",
       "      <td>Acoustic_guitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23151</th>\n",
       "      <td>fffd1871.wav</td>\n",
       "      <td>Water_tap_and_faucet,Sink_(filling_or_washing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23152</th>\n",
       "      <td>fffe9808.wav</td>\n",
       "      <td>Clapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23153</th>\n",
       "      <td>ffff6da3.wav</td>\n",
       "      <td>Walk_and_footsteps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              fname                                          labels\n",
       "0      0006ae4e.wav                                            Bark\n",
       "1      0019ef41.wav                                        Raindrop\n",
       "2      001ec0ad.wav                                 Finger_snapping\n",
       "3      0026c7cb.wav                                             Run\n",
       "4      0026f116.wav                                 Finger_snapping\n",
       "...             ...                                             ...\n",
       "23149  fffc7128.wav                                       Accordion\n",
       "23150  fffcf57b.wav                                 Acoustic_guitar\n",
       "23151  fffd1871.wav  Water_tap_and_faucet,Sink_(filling_or_washing)\n",
       "23152  fffe9808.wav                                        Clapping\n",
       "23153  ffff6da3.wav                              Walk_and_footsteps\n",
       "\n",
       "[23154 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "import warnings\n",
    "import os\n",
    "def drop_unloadable_files(df, audio_dir):\n",
    "    # Iterate over the DataFrame\n",
    "    for i, row in df.iterrows():\n",
    "        audio_file = os.path.join(audio_dir, row['fname'])\n",
    "        try:\n",
    "            # Try to load the audio file\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter('ignore')\n",
    "                librosa.load(audio_file, sr=None)\n",
    "        except Exception:\n",
    "            # If loading fails, drop the row\n",
    "            df = df.drop(i)\n",
    "    return df\n",
    "\n",
    "# Drop rows with unloadable audio files from the curated and noisy DataFrames\n",
    "df_curated = drop_unloadable_files(df_curated, audio_path_curated)\n",
    "df_noisy = drop_unloadable_files(df_noisy, audio_path_noisy)\n",
    "\n",
    "# Concatenate the curated and noisy DataFrames\n",
    "df = pd.concat([df_curated, df_noisy], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>...</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ae4e.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0019ef41.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ec0ad.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0026c7cb.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0026f116.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23149</th>\n",
       "      <td>fffc7128.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23150</th>\n",
       "      <td>fffcf57b.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23151</th>\n",
       "      <td>fffd1871.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23152</th>\n",
       "      <td>fffe9808.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23153</th>\n",
       "      <td>ffff6da3.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23154 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              fname  Accelerating_and_revving_and_vroom  Accordion  \\\n",
       "0      0006ae4e.wav                                   0          0   \n",
       "1      0019ef41.wav                                   0          0   \n",
       "2      001ec0ad.wav                                   0          0   \n",
       "3      0026c7cb.wav                                   0          0   \n",
       "4      0026f116.wav                                   0          0   \n",
       "...             ...                                 ...        ...   \n",
       "23149  fffc7128.wav                                   0          1   \n",
       "23150  fffcf57b.wav                                   0          0   \n",
       "23151  fffd1871.wav                                   0          0   \n",
       "23152  fffe9808.wav                                   0          0   \n",
       "23153  ffff6da3.wav                                   0          0   \n",
       "\n",
       "       Acoustic_guitar  Applause  Bark  Bass_drum  Bass_guitar  \\\n",
       "0                    0         0     1          0            0   \n",
       "1                    0         0     0          0            0   \n",
       "2                    0         0     0          0            0   \n",
       "3                    0         0     0          0            0   \n",
       "4                    0         0     0          0            0   \n",
       "...                ...       ...   ...        ...          ...   \n",
       "23149                0         0     0          0            0   \n",
       "23150                1         0     0          0            0   \n",
       "23151                0         0     0          0            0   \n",
       "23152                0         0     0          0            0   \n",
       "23153                0         0     0          0            0   \n",
       "\n",
       "       Bathtub_(filling_or_washing)  Bicycle_bell  ...  Toilet_flush  \\\n",
       "0                                 0             0  ...             0   \n",
       "1                                 0             0  ...             0   \n",
       "2                                 0             0  ...             0   \n",
       "3                                 0             0  ...             0   \n",
       "4                                 0             0  ...             0   \n",
       "...                             ...           ...  ...           ...   \n",
       "23149                             0             0  ...             0   \n",
       "23150                             0             0  ...             0   \n",
       "23151                             0             0  ...             0   \n",
       "23152                             0             0  ...             0   \n",
       "23153                             0             0  ...             0   \n",
       "\n",
       "       Traffic_noise_and_roadway_noise  Trickle_and_dribble  \\\n",
       "0                                    0                    0   \n",
       "1                                    0                    0   \n",
       "2                                    0                    0   \n",
       "3                                    0                    0   \n",
       "4                                    0                    0   \n",
       "...                                ...                  ...   \n",
       "23149                                0                    0   \n",
       "23150                                0                    0   \n",
       "23151                                0                    0   \n",
       "23152                                0                    0   \n",
       "23153                                0                    0   \n",
       "\n",
       "       Walk_and_footsteps  Water_tap_and_faucet  Waves_and_surf  Whispering  \\\n",
       "0                       0                     0               0           0   \n",
       "1                       0                     0               0           0   \n",
       "2                       0                     0               0           0   \n",
       "3                       0                     0               0           0   \n",
       "4                       0                     0               0           0   \n",
       "...                   ...                   ...             ...         ...   \n",
       "23149                   0                     0               0           0   \n",
       "23150                   0                     0               0           0   \n",
       "23151                   0                     1               0           0   \n",
       "23152                   0                     0               0           0   \n",
       "23153                   1                     0               0           0   \n",
       "\n",
       "       Writing  Yell  Zipper_(clothing)  \n",
       "0            0     0                  0  \n",
       "1            0     0                  0  \n",
       "2            0     0                  0  \n",
       "3            0     0                  0  \n",
       "4            0     0                  0  \n",
       "...        ...   ...                ...  \n",
       "23149        0     0                  0  \n",
       "23150        0     0                  0  \n",
       "23151        0     0                  0  \n",
       "23152        0     0                  0  \n",
       "23153        0     0                  0  \n",
       "\n",
       "[23154 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Split the labels on the commas to create a list of labels for each sample\n",
    "df['labels'] = df['labels'].str.split(',')\n",
    "\n",
    "# Create a MultiLabelBinarizer object\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# One-hot encode the labels\n",
    "df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('labels')),\n",
    "                          columns=mlb.classes_,\n",
    "                          index=df.index))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_and_fix_length(fname, duration=2, sr=22050):\n",
    "    # Paths to the audio files\n",
    "    audio_path_curated = '/Users/owo/HOUSE/@DUNE/@AI/Sound Classification2/freesound-audio-tagging-2019/train_curated'\n",
    "    audio_path_noisy = '/Users/owo/HOUSE/@DUNE/@AI/Sound Classification2/freesound-audio-tagging-2019/train_noisy'\n",
    "    \n",
    "    # Check if the file exists in the curated directory\n",
    "    if os.path.exists(os.path.join(audio_path_curated, fname)):\n",
    "        filename = os.path.join(audio_path_curated, fname)\n",
    "    # Otherwise, check the noisy directory\n",
    "    elif os.path.exists(os.path.join(audio_path_noisy, fname)):\n",
    "        filename = os.path.join(audio_path_noisy, fname)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{fname} not found in both directories.\")\n",
    "    \n",
    "    # Load the audio file\n",
    "    y, _ = librosa.load(filename, sr=sr)\n",
    "\n",
    "    # If the audio is too short, pad it with zeros\n",
    "    if len(y) < sr * duration:\n",
    "        y = np.pad(y, (0, int(sr * duration) - len(y)))\n",
    "    # If the audio is too long, truncate it\n",
    "    elif len(y) > sr * duration:\n",
    "        y = y[:int(sr * duration)]\n",
    "    \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel_spectrogram(y, sr=22050, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    # Compute the spectrogram\n",
    "    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    D_abs = np.abs(D)\n",
    "    # Convert to Mel scale\n",
    "    mel_spec = librosa.feature.melspectrogram(S=librosa.amplitude_to_db(D_abs), sr=sr, n_mels=n_mels)\n",
    "    return mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your own spectrogram computation\n",
    "spectrograms = [get_mel_spectrogram(load_and_fix_length(filename)) for filename in df['fname']]\n",
    "#labels_encoded = mlb.transform(df['labels'])\n",
    "#spectrograms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AudioClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(128*32*21, 1024)\n",
    "        self.fc2 = nn.Linear(1024, len(mlb.classes_))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add an extra dimension for the single channel\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_and_fix_length(fname, duration=2, sr=22050):\n",
    "    # Paths to the audio files\n",
    "    audio_path_curated = '/Users/owo/HOUSE/@DUNE/@AI/Sound Classification2/freesound-audio-tagging-2019/train_curated'\n",
    "    audio_path_noisy = '/Users/owo/HOUSE/@DUNE/@AI/Sound Classification2/freesound-audio-tagging-2019/train_noisy'\n",
    "    \n",
    "    # Check if the file exists in the curated directory\n",
    "    if os.path.exists(os.path.join(audio_path_curated, fname)):\n",
    "        filename = os.path.join(audio_path_curated, fname)\n",
    "    # Otherwise, check the noisy directory\n",
    "    elif os.path.exists(os.path.join(audio_path_noisy, fname)):\n",
    "        filename = os.path.join(audio_path_noisy, fname)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{fname} not found in both directories.\")\n",
    "    \n",
    "    # Load the audio file\n",
    "    y, _ = librosa.load(filename, sr=sr)\n",
    "\n",
    "    # If the audio is too short, pad it with zeros\n",
    "    if len(y) < sr * duration:\n",
    "        y = np.pad(y, (0, int(sr * duration) - len(y)))\n",
    "    # If the audio is too long, truncate it\n",
    "    elif len(y) > sr * duration:\n",
    "        y = y[:int(sr * duration)]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a labels DataFrame\n",
    "labels = df.drop(columns='fname')\n",
    "\n",
    "# Convert the spectrograms and labels to numpy arrays\n",
    "X = np.array(spectrograms)\n",
    "y = labels.to_numpy()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert the training and validation sets to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# Create PyTorch datasets from the tensors\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# Create PyTorch dataloaders from the datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 87])\n",
      "torch.Size([32, 128, 87])\n",
      "torch.Size([32, 128, 87])\n",
      "torch.Size([32, 128, 87])\n",
      "torch.Size([32, 128, 87])\n",
      "torch.Size([32, 128, 87])\n",
      "torch.Size([32, 128, 87])\n",
      "torch.Size([32, 128, 87])\n",
      "torch.Size([32, 128, 87])\n",
      "torch.Size([32, 128, 87])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     40\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 42\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     44\u001b[0m train_loss \u001b[39m=\u001b[39m running_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n\u001b[1;32m     45\u001b[0m train_losses\u001b[39m.\u001b[39mappend(train_loss)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'mps'\n",
    "# Create the model, loss function and optimizer\n",
    "model = AudioClassifier().to(device)\n",
    "if torch.cuda.device_count() > 1:  # Check if multiple GPUs are available\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = DataParallel(model)\n",
    "    \n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "# For storing losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1\n",
    "best_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        print(inputs.shape)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    val_loss = running_loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # Save the model if it's the best so far\n",
    "    if val_loss < best_loss:\n",
    "        torch.save(model.state_dict(), 'AI2.pth')\n",
    "        best_loss = val_loss\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    estimated_time = elapsed_time * (num_epochs - epoch - 1)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.2f}, Val Loss: {val_loss:.2f}, Elapsed Time: {elapsed_time:.2f}s, Estimated Time Left: {estimated_time:.2f}s\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the losses\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('train_noisy.csv')\n",
    "\n",
    "# Split the labels on the commas to create a list of labels for each sample\n",
    "df['labels'] = df['labels'].str.split(',')\n",
    "\n",
    "# Get unique labels\n",
    "labels = pd.unique(df['labels'].explode())\n",
    "\n",
    "# Create and fit the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88200, 1)\n",
      "(88200,)\n",
      "(44100,)\n",
      "(128, 87)\n",
      "torch.Size([1, 128, 87])\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This LabelEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m probs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     40\u001b[0m top_prob, top_label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(probs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredicted label: \u001b[39m\u001b[39m{\u001b[39;00mle\u001b[39m.\u001b[39minverse_transform([top_label\u001b[39m.\u001b[39mitem()])[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProbability: \u001b[39m\u001b[39m{\u001b[39;00mtop_prob\u001b[39m.\u001b[39mitem()\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torchenv/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:152\u001b[0m, in \u001b[0;36mLabelEncoder.inverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse_transform\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[1;32m    140\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Transform labels back to original encoding.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m        Original encoding.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    153\u001b[0m     y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    154\u001b[0m     \u001b[39m# inverse transform of empty array is empty array\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torchenv/lib/python3.11/site-packages/sklearn/utils/validation.py:1462\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not an estimator instance.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (estimator))\n\u001b[1;32m   1461\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1462\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This LabelEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def get_mel_spectrogram(y, sr=22050, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    # Compute the spectrogram\n",
    "    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    D_abs = np.abs(D)\n",
    "    # Convert to Mel scale\n",
    "    mel_spec = librosa.feature.melspectrogram(S=librosa.amplitude_to_db(D_abs), sr=sr, n_mels=n_mels)\n",
    "    return mel_spec\n",
    "\n",
    "#le = LabelEncoder()\n",
    "\n",
    "# Load the trained model\n",
    "model = AudioClassifier()\n",
    "model.load_state_dict(torch.load('AI2.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Record audio\n",
    "duration = 2  # seconds\n",
    "fs = 44100  # Sample rate\n",
    "recording = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "sd.wait()  # Wait until recording is finished\n",
    "print(recording.shape)\n",
    "# Preprocess audio\n",
    "recording = np.squeeze(recording)  # Remove the singleton dimension\n",
    "print(recording.shape)\n",
    "recording = librosa.resample(recording, orig_sr=fs, target_sr=22050)  # Resample the recording\n",
    "print(recording.shape)\n",
    "mel_spec = get_mel_spectrogram(recording)  # Compute the Mel spectrogram\n",
    "print(mel_spec.shape)\n",
    "# Make prediction\n",
    "mel_spec = torch.from_numpy(mel_spec).unsqueeze(0).float()  # Add two singleton dimensions at the beginning\n",
    "print(mel_spec.shape)\n",
    "outputs = model(mel_spec)\n",
    "probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "top_prob, top_label = torch.max(probs, dim=1)\n",
    "\n",
    "print(f\"Predicted label: {le.inverse_transform([top_label.item()])[0]}\")\n",
    "print(f\"Probability: {top_prob.item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Acoustic_guitar\n",
      "Probability: 52.98%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('train_noisy.csv')\n",
    "\n",
    "# Split the labels on the commas to create a list of labels for each sample\n",
    "df['labels'] = df['labels'].str.split(',')\n",
    "\n",
    "# Get unique labels\n",
    "labels = pd.unique(df['labels'].explode())\n",
    "\n",
    "# Create and fit the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(labels)\n",
    "\n",
    "import sounddevice as sd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_mel_spectrogram(y, sr=22050, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    # Compute the spectrogram\n",
    "    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    D_abs = np.abs(D)\n",
    "    # Convert to Mel scale\n",
    "    mel_spec = librosa.feature.melspectrogram(S=librosa.amplitude_to_db(D_abs), sr=sr, n_mels=n_mels)\n",
    "    return mel_spec\n",
    "\n",
    "# Load the trained model\n",
    "model = AudioClassifier()\n",
    "model.load_state_dict(torch.load('AI2.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Record audio\n",
    "duration = 2  # seconds\n",
    "fs = 44100  # Sample rate\n",
    "recording = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "sd.wait()  # Wait until recording is finished\n",
    "\n",
    "# Preprocess audio\n",
    "recording = np.squeeze(recording)  # Remove the singleton dimension\n",
    "recording = librosa.resample(recording, orig_sr=fs, target_sr=22050)  # Resample the recording\n",
    "mel_spec = get_mel_spectrogram(recording)  # Compute the Mel spectrogram\n",
    "\n",
    "# Make prediction\n",
    "mel_spec = torch.from_numpy(mel_spec).unsqueeze(0).float()  # Add two singleton dimensions at the beginning\n",
    "outputs = model(mel_spec)\n",
    "probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "top_prob, top_label = torch.max(probs, dim=1)\n",
    "\n",
    "print(f\"Predicted label: {le.inverse_transform([top_label.item()])[0]}\")\n",
    "print(f\"Probability: {top_prob.item() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diary\n",
    "2023.07.24 0109i\n",
    "\n",
    "I honestly spent like 15 hours to make this today. It took a lot of time but since I did 'urban 8 sound' before. It was slightly OK but still frustrating. I was almost done finishing this project then I noticed that some of the label has MORE than one label at a time. Then I have to do this whole thing over again . That was my first drag, and the second drag was at the fact I accidentally deleted the whole thing pressing undo in GitHub. Thankfully I had all the things in chat GPT, so that from there I was easily recovered.  \n",
    "I still have a problem with real time analizer but I can sort it out later  \n",
    "I have to go to work tommorrow, I have to go to sleep.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
