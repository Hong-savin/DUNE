{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owo/anaconda3/envs/torchenv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/owo/anaconda3/envs/torchenv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded.+CPU\n"
     ]
    }
   ],
   "source": [
    "#DEIVCE + MODEL READY\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import sounddevice as sd\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "try:\n",
    "    # MULTI GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = resnet18(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(512, 10)\n",
    "    model = nn.DataParallel(model)  # Add this line\n",
    "    model.load_state_dict(torch.load('ResNet18_Best.pth', map_location=device))\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "\n",
    "    state_dict = torch.load('ResNet18_Best.pth', map_location=device)\n",
    "    new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "    print(\"Model successfully loaded. + GPU\")\n",
    "except:\n",
    "    #One GPU or CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = resnet18(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(512, 10)\n",
    "    try:\n",
    "        state_dict = torch.load('ResNet18_Best.pth', map_location=device)\n",
    "        new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "        model.load_state_dict(new_state_dict)\n",
    "        model = model.to(device)\n",
    "        model = model.eval()\n",
    "        print(\"Model successfully loaded.+CPU\")\n",
    "    except:\n",
    "        print(\"Failed to load the model. Please check the model file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owo/anaconda3/envs/torchenv/lib/python3.11/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Transform\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "class MonoToColor(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(MonoToColor, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.repeat(self.num_channels, 1, 1)\n",
    "\n",
    "# Apply the same transformation as used during training\n",
    "transformation = transforms.Compose([\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=128),\n",
    "    torchaudio.transforms.AmplitudeToDB(stype='power', top_db=80),\n",
    "    MonoToColor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in sound asis\n",
      "out of run2\n",
      "in mian\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "The predicted class is: dog_bark, with confidence: 45.71%\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "Received signal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.fonts: Populating font family aliases took 64 ms. Replace uses of missing font family \"AppleSystemUIFont\" with one that exists to avoid this cost. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "The predicted class is: drilling, with confidence: 99.87%\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "Received signal\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "The predicted class is: drilling, with confidence: 99.99%\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "Received signal\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "The predicted class is: drilling, with confidence: 99.98%\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "Received signal\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "The predicted class is: dog_bark, with confidence: 37.08%\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "Received signal\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "The predicted class is: siren, with confidence: 99.61%\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "Received signal\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "The predicted class is: siren, with confidence: 97.24%\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 143\u001b[0m, in \u001b[0;36mUi_MainWindow.updateLabel\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msound_analysis\u001b[39m.\u001b[39mresult_signal\u001b[39m.\u001b[39mconnect(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdateLabel)\n\u001b[1;32m    141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msound_analysis\u001b[39m.\u001b[39mstart()  \u001b[39m# Start the sound analysis thread\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdateLabel\u001b[39m(\u001b[39mself\u001b[39m, text):\n\u001b[1;32m    144\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mReceived signal\u001b[39m\u001b[39m\"\u001b[39m)  \u001b[39m# Print message when signal is received\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel\u001b[39m.\u001b[39msetText(text)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "The predicted class is: drilling, with confidence: 48.57%\n",
      "21\n",
      "pass\n",
      "1\n",
      "SoundAnalysis thread started\n",
      "2\n",
      "Received signal\n"
     ]
    }
   ],
   "source": [
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from PyQt5.QtCore import QThread, pyqtSignal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import sounddevice as sd\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.autograd import Variable\n",
    "\n",
    "sample_rate = SAMPLE_RATE\n",
    "target_sample_rate = SAMPLE_RATE\n",
    "\n",
    "# Sound Analysis class running on a separate thread\n",
    "class SoundAnalysis(QThread):\n",
    "    print(\"in sound asis\")\n",
    "    # Define a pyqtSignal with str type, which will be used to send the analysis results to the main thread\n",
    "    result_signal = pyqtSignal(str)\n",
    "\n",
    "    def __init__(self, model, device, transformation, sample_rate):\n",
    "        QThread.__init__(self)\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.transformation = transformation\n",
    "        self.sample_rate = sample_rate\n",
    "    def run(self):\n",
    "        try:\n",
    "            while True:\n",
    "                print(1)  # Print 1\n",
    "                print(\"SoundAnalysis thread started\")  # Print message at start of thread\n",
    "\n",
    "                import time\n",
    "                import torch.nn.functional as F\n",
    "\n",
    "                class_labels = ['air_conditioner', 'car_horn', 'children_playing', 'dog_bark', 'drilling', \n",
    "                                'engine_idling', 'gun_shot', 'jackhammer', 'siren', 'street_music']\n",
    "\n",
    "                print(2)  # Print 2\n",
    "\n",
    "                # Record a 2 seconds mono audio at the specified sample rate\n",
    "                duration = 2.0  # seconds\n",
    "                recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1) \n",
    "                sd.wait()\n",
    "\n",
    "                print(3)  # Print 3\n",
    "\n",
    "                # Convert to PyTorch tensor and switch channels and frames\n",
    "                recording = torch.from_numpy(recording).float()\n",
    "                recording = torch.transpose(recording, 0, 1)\n",
    "\n",
    "                print(4)  # Print 4\n",
    "\n",
    "                # Resample if necessary\n",
    "                if sample_rate != target_sample_rate:\n",
    "                    resampler = torchaudio.transforms.Resample(sample_rate, target_sample_rate)\n",
    "                    recording = resampler(recording)\n",
    "\n",
    "                print(5)  # Print 5\n",
    "\n",
    "                # Mix down if necessary\n",
    "                if recording.shape[0] > 1:\n",
    "                    recording = torch.mean(recording, dim=0, keepdim=True)\n",
    "\n",
    "                print(6)  # Print 6\n",
    "\n",
    "                # Cut or pad if necessary\n",
    "                if recording.shape[1] > target_sample_rate:\n",
    "                    recording = recording[:, :target_sample_rate]\n",
    "                elif recording.shape[1] < target_sample_rate:\n",
    "                    num_missing_samples = target_sample_rate - recording.shape[1]\n",
    "                    last_dim_padding = (0, num_missing_samples)\n",
    "                    recording = nn.functional.pad(recording, last_dim_padding)\n",
    "\n",
    "                print(7)  # Print 7\n",
    "\n",
    "                # Apply transformation\n",
    "                recording = transformation(recording)\n",
    "\n",
    "                print(8)  # Print 8\n",
    "\n",
    "                # Make the prediction\n",
    "                model.eval()  # set model to evaluation mode\n",
    "                with torch.no_grad():  # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "                    recording = recording.to(device)\n",
    "                    outputs = model(recording[None, ...])\n",
    "                    probabilities = F.softmax(outputs, dim=1)  # apply softmax to output\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                print(9)  # Print 9\n",
    "\n",
    "                # Get predicted label and its corresponding probability\n",
    "                predicted_label = class_labels[predicted.item()]\n",
    "                predicted_confidence = probabilities[0, predicted.item()].item()  # get the probability of the predicted class\n",
    "\n",
    "                print(10)  # Print 10\n",
    "\n",
    "                # Only print the output if the confidence is greater than 80% and the label is not in the specified list\n",
    "                if predicted_confidence >= 0.0 and predicted_label not in ['air_conditioner', 'children_playing', 'street_music']:\n",
    "                    print(f\"The predicted class is: {predicted_label}, with confidence: {predicted_confidence:.2%}\")\n",
    "                    self.result_signal.emit(f\"The predicted class is: {predicted_label}\")\n",
    "                print(21)\n",
    "                pass\n",
    "                print('pass')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred in SoundAnalysis thread: {e}\")\n",
    "            print(f\"Exception occurred in SoundAnalysis thread: {e}\")\n",
    "        #pass\n",
    "        print('end run')\n",
    "    print('out of run2')\n",
    "\n",
    "class Ui_MainWindow(object):\n",
    "    def setupUi(self, MainWindow):\n",
    "        MainWindow.setObjectName(\"MainWindow\")\n",
    "        MainWindow.resize(800, 600)\n",
    "        self.centralwidget = QtWidgets.QWidget(MainWindow)\n",
    "        self.centralwidget.setObjectName(\"centralwidget\")\n",
    "        self.graphicsView = QtWidgets.QGraphicsView(self.centralwidget)\n",
    "        self.graphicsView.setGeometry(QtCore.QRect(120, 50, 571, 261))\n",
    "        self.graphicsView.setFrameShadow(QtWidgets.QFrame.Plain)\n",
    "        self.graphicsView.setObjectName(\"graphicsView\")\n",
    "        self.label = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.label.setGeometry(QtCore.QRect(150, 381, 471, 61))\n",
    "        self.label.setFrameShadow(QtWidgets.QFrame.Sunken)\n",
    "        self.label.setObjectName(\"label\")\n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "        self.menubar = QtWidgets.QMenuBar(MainWindow)\n",
    "        self.menubar.setGeometry(QtCore.QRect(0, 0, 800, 29))\n",
    "        self.menubar.setObjectName(\"menubar\")\n",
    "        MainWindow.setMenuBar(self.menubar)\n",
    "        self.statusbar = QtWidgets.QStatusBar(MainWindow)\n",
    "        self.statusbar.setObjectName(\"statusbar\")\n",
    "        MainWindow.setStatusBar(self.statusbar)\n",
    "\n",
    "        self.retranslateUi(MainWindow)\n",
    "        QtCore.QMetaObject.connectSlotsByName(MainWindow)\n",
    "\n",
    "        # Initialize SoundAnalysis and connect the result_signal with the updateLabel function\n",
    "        self.sound_analysis = SoundAnalysis(model, device, transformation, SAMPLE_RATE)\n",
    "        self.sound_analysis.result_signal.connect(self.updateLabel)\n",
    "        self.sound_analysis.start()  # Start the sound analysis thread\n",
    "\n",
    "    def updateLabel(self, text):\n",
    "        print(\"Received signal\")  # Print message when signal is received\n",
    "        self.label.setText(text)\n",
    "\n",
    "    def retranslateUi(self, MainWindow):\n",
    "        print(11)\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        print(12)\n",
    "        MainWindow.setWindowTitle(_translate(\"MainWindow\", \"MainWindow\"))\n",
    "        print(13)\n",
    "        self.label.setFont(QtGui.QFont(\"AppleSystemUIFont\",30))\n",
    "        print(14)\n",
    "        self.label.setStyleSheet(\"Color : black\")\n",
    "        print(15)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"in mian\")\n",
    "    import sys\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    MainWindow = QtWidgets.QMainWindow()\n",
    "    ui = Ui_MainWindow()\n",
    "    ui.setupUi(MainWindow)\n",
    "    MainWindow.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.AppleSystemUIFont', 'Academy Engraved LET', 'Al Bayan', 'Al Nile', 'Al Tarikh', 'American Typewriter', 'Andale Mono', 'Apple Braille', 'Apple Chancery', 'Apple Color Emoji', 'Apple SD Gothic Neo', 'Apple Symbols', 'AppleGothic', 'AppleMyungjo', 'Arial', 'Arial Black', 'Arial Hebrew', 'Arial Hebrew Scholar', 'Arial Narrow', 'Arial Rounded MT Bold', 'Arial Unicode MS', 'Avenir', 'Avenir Next', 'Avenir Next Condensed', 'Ayuthaya', 'Baghdad', 'Bangla MN', 'Bangla Sangam MN', 'Baskerville', 'Beirut', 'Big Caslon', 'Bodoni 72', 'Bodoni 72 Oldstyle', 'Bodoni 72 Smallcaps', 'Bodoni Ornaments', 'Bradley Hand', 'Brush Script MT', 'Chalkboard', 'Chalkboard SE', 'Chalkduster', 'Charter', 'Cochin', 'Comic Sans MS', 'Copperplate', 'Corsiva Hebrew', 'Courier New', 'Damascus', 'DecoType Naskh', 'Devanagari MT', 'Devanagari Sangam MN', 'Didot', 'DIN Alternate', 'DIN Condensed', 'Diwan Kufi', 'Diwan Thuluth', 'Euphemia UCAS', 'Farah', 'Farisi', 'Futura', 'Galvji', 'GB18030 Bitmap', 'Geeza Pro', 'Geneva', 'Georgia', 'Gill Sans', 'Grantha Sangam MN', 'Gujarati MT', 'Gujarati Sangam MN', 'Gurmukhi MN', 'Gurmukhi MT', 'Gurmukhi Sangam MN', 'Heiti SC', 'Heiti TC', 'Helvetica', 'Helvetica Neue', 'Herculanum', 'Hiragino Maru Gothic ProN', 'Hiragino Mincho ProN', 'Hiragino Sans', 'Hiragino Sans GB', 'Hoefler Text', 'Impact', 'InaiMathi', 'ITF Devanagari', 'ITF Devanagari Marathi', 'Kailasa', 'Kannada MN', 'Kannada Sangam MN', 'Kefa', 'Khmer MN', 'Khmer Sangam MN', 'Kohinoor Bangla', 'Kohinoor Devanagari', 'Kohinoor Gujarati', 'Kohinoor Telugu', 'Kokonor', 'Krungthep', 'KufiStandardGK', 'Lao MN', 'Lao Sangam MN', 'Lucida Grande', 'Luminari', 'Malayalam MN', 'Malayalam Sangam MN', 'Marker Felt', 'Menlo', 'Microsoft Sans Serif', 'Mishafi', 'Mishafi Gold', 'Monaco', 'Mshtakan', 'Mukta Mahee', 'Muna', 'Myanmar MN', 'Myanmar Sangam MN', 'Nadeem', 'New Peninim MT', 'Noteworthy', 'Noto Nastaliq Urdu', 'Noto Sans Kannada', 'Noto Sans Myanmar', 'Noto Sans Oriya', 'Noto Serif Myanmar', 'Optima', 'Oriya MN', 'Oriya Sangam MN', 'Palatino', 'Papyrus', 'Party LET', 'Phosphate', 'PingFang HK', 'PingFang SC', 'PingFang TC', 'Plantagenet Cherokee', 'PT Mono', 'PT Sans', 'PT Sans Caption', 'PT Sans Narrow', 'PT Serif', 'PT Serif Caption', 'Raanana', 'Rockwell', 'Sana', 'Sathu', 'Savoye LET', 'Shree Devanagari 714', 'SignPainter', 'Silom', 'Sinhala MN', 'Sinhala Sangam MN', 'Skia', 'Snell Roundhand', 'Songti SC', 'Songti TC', 'STIX Two Math', 'STIX Two Text', 'STSong', 'Sukhumvit Set', 'Symbol', 'Tahoma', 'Tamil MN', 'Tamil Sangam MN', 'Telugu MN', 'Telugu Sangam MN', 'Thonburi', 'Times New Roman', 'Trattatello', 'Trebuchet MS', 'Verdana', 'Waseem', 'Webdings', 'Wingdings', 'Wingdings 2', 'Wingdings 3', 'Zapf Dingbats', 'Zapfino']\n"
     ]
    }
   ],
   "source": [
    "from PyQt5.QtGui import QFontDatabase\n",
    "\n",
    "print(QFontDatabase().families())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
