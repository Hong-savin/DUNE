{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded.+CPU\n"
     ]
    }
   ],
   "source": [
    "#DEIVCE + MODEL READY\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import sounddevice as sd\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "try:\n",
    "    # MULTI GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = resnet18(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(512, 10)\n",
    "    model = nn.DataParallel(model)  # Add this line\n",
    "    model.load_state_dict(torch.load('ResNet18_Best.pth', map_location=device))\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "\n",
    "    state_dict = torch.load('ResNet18_Best.pth', map_location=device)\n",
    "    new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "    print(\"Model successfully loaded. + GPU\")\n",
    "except:\n",
    "    #One GPU or CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = resnet18(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(512, 10)\n",
    "    try:\n",
    "        state_dict = torch.load('ResNet18_Best.pth', map_location=device)\n",
    "        new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "        model.load_state_dict(new_state_dict)\n",
    "        model = model.to(device)\n",
    "        model = model.eval()\n",
    "        print(\"Model successfully loaded.+CPU\")\n",
    "    except:\n",
    "        print(\"Failed to load the model. Please check the model file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "class MonoToColor(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(MonoToColor, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.repeat(self.num_channels, 1, 1)\n",
    "\n",
    "# Apply the same transformation as used during training\n",
    "transformation = transforms.Compose([\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=128),\n",
    "    torchaudio.transforms.AmplitudeToDB(stype='power', top_db=80),\n",
    "    MonoToColor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoundAnalysis thread started\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owo/anaconda3/envs/torchenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from PyQt5.QtCore import QThread, pyqtSignal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import sounddevice as sd\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.autograd import Variable\n",
    "\n",
    "sample_rate = SAMPLE_RATE\n",
    "target_sample_rate = SAMPLE_RATE\n",
    "\n",
    "# Sound Analysis class running on a separate thread\n",
    "class SoundAnalysis(QThread):\n",
    "    # Define a pyqtSignal with str type, which will be used to send the analysis results to the main thread\n",
    "    result_signal = pyqtSignal(str)\n",
    "\n",
    "    def __init__(self, model, device, transformation, sample_rate):\n",
    "        QThread.__init__(self)\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.transformation = transformation\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            print(\"SoundAnalysis thread started\")  # Print message at start of thread\n",
    "\n",
    "            import time\n",
    "            import torch.nn.functional as F\n",
    "\n",
    "            class_labels = ['air_conditioner', 'car_horn', 'children_playing', 'dog_bark', 'drilling', \n",
    "                            'engine_idling', 'gun_shot', 'jackhammer', 'siren', 'street_music']\n",
    "            \n",
    "            # Record a 2 seconds mono audio at the specified sample rate\n",
    "            duration = 2.0  # seconds\n",
    "            recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1) \n",
    "            sd.wait()\n",
    "\n",
    "            # Convert to PyTorch tensor and switch channels and frames\n",
    "            recording = torch.from_numpy(recording).float()\n",
    "            recording = torch.transpose(recording, 0, 1)\n",
    "\n",
    "            # Resample if necessary\n",
    "            if sample_rate != target_sample_rate:\n",
    "                resampler = torchaudio.transforms.Resample(sample_rate, target_sample_rate)\n",
    "                recording = resampler(recording)\n",
    "\n",
    "            # Mix down if necessary\n",
    "            if recording.shape[0] > 1:\n",
    "                recording = torch.mean(recording, dim=0, keepdim=True)\n",
    "\n",
    "            # Cut or pad if necessary\n",
    "            if recording.shape[1] > target_sample_rate:\n",
    "                recording = recording[:, :target_sample_rate]\n",
    "            elif recording.shape[1] < target_sample_rate:\n",
    "                num_missing_samples = target_sample_rate - recording.shape[1]\n",
    "                last_dim_padding = (0, num_missing_samples)\n",
    "                recording = nn.functional.pad(recording, last_dim_padding)\n",
    "\n",
    "            # Apply transformation\n",
    "            recording = transformation(recording)\n",
    "\n",
    "            # Make the prediction\n",
    "            model.eval()  # set model to evaluation mode\n",
    "            with torch.no_grad():  # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "                recording = recording.to(device)\n",
    "                outputs = model(recording[None, ...])\n",
    "                probabilities = F.softmax(outputs, dim=1)  # apply softmax to output\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Get predicted label and its corresponding probability\n",
    "            predicted_label = class_labels[predicted.item()]\n",
    "            predicted_confidence = probabilities[0, predicted.item()].item()  # get the probability of the predicted class\n",
    "\n",
    "            # Only print the output if the confidence is greater than 80% and the label is not in the specified list\n",
    "            if predicted_confidence >= 0.0 and predicted_label not in ['air_conditioner', 'children_playing', 'street_music']:#THE EXCLUDED LABLES\n",
    "                print(f\"The predicted class is: {predicted_label}, with confidence: {predicted_confidence:.2%}\")  # Print message before emitting signal\n",
    "                self.result_signal.emit(f\"The predicted class is: {predicted_label}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred in SoundAnalysis thread: {e}\")\n",
    "        #pass\n",
    "\n",
    "class Ui_MainWindow(object):\n",
    "    def setupUi(self, MainWindow):\n",
    "        MainWindow.setObjectName(\"MainWindow\")\n",
    "        MainWindow.resize(800, 600)\n",
    "        self.centralwidget = QtWidgets.QWidget(MainWindow)\n",
    "        self.centralwidget.setObjectName(\"centralwidget\")\n",
    "        self.graphicsView = QtWidgets.QGraphicsView(self.centralwidget)\n",
    "        self.graphicsView.setGeometry(QtCore.QRect(120, 50, 571, 261))\n",
    "        self.graphicsView.setFrameShadow(QtWidgets.QFrame.Plain)\n",
    "        self.graphicsView.setObjectName(\"graphicsView\")\n",
    "        self.label = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.label.setGeometry(QtCore.QRect(150, 381, 471, 61))\n",
    "        self.label.setFrameShadow(QtWidgets.QFrame.Sunken)\n",
    "        self.label.setObjectName(\"label\")\n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "        self.menubar = QtWidgets.QMenuBar(MainWindow)\n",
    "        self.menubar.setGeometry(QtCore.QRect(0, 0, 800, 29))\n",
    "        self.menubar.setObjectName(\"menubar\")\n",
    "        MainWindow.setMenuBar(self.menubar)\n",
    "        self.statusbar = QtWidgets.QStatusBar(MainWindow)\n",
    "        self.statusbar.setObjectName(\"statusbar\")\n",
    "        MainWindow.setStatusBar(self.statusbar)\n",
    "\n",
    "        self.retranslateUi(MainWindow)\n",
    "        QtCore.QMetaObject.connectSlotsByName(MainWindow)\n",
    "\n",
    "        # Initialize SoundAnalysis and connect the result_signal with the updateLabel function\n",
    "        self.sound_analysis = SoundAnalysis(model, device, transformation, SAMPLE_RATE)\n",
    "        self.sound_analysis.result_signal.connect(self.updateLabel)\n",
    "        self.sound_analysis.start()  # Start the sound analysis thread\n",
    "\n",
    "    def updateLabel(self, text):\n",
    "        print(\"Received signal\")  # Print message when signal is received\n",
    "        self.label.setText(text)\n",
    "\n",
    "    def retranslateUi(self, MainWindow):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        MainWindow.setWindowTitle(_translate(\"MainWindow\", \"MainWindow\"))\n",
    "        self.label.setFont(QtGui.QFont(\"AppleSystemUIFont\",30))\n",
    "        self.label.setStyleSheet(\"Color : black\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    MainWindow = QtWidgets.QMainWindow()\n",
    "    ui = Ui_MainWindow()\n",
    "    ui.setupUi(MainWindow)\n",
    "    MainWindow.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.AppleSystemUIFont', 'Academy Engraved LET', 'Al Bayan', 'Al Nile', 'Al Tarikh', 'American Typewriter', 'Andale Mono', 'Apple Braille', 'Apple Chancery', 'Apple Color Emoji', 'Apple SD Gothic Neo', 'Apple Symbols', 'AppleGothic', 'AppleMyungjo', 'Arial', 'Arial Black', 'Arial Hebrew', 'Arial Hebrew Scholar', 'Arial Narrow', 'Arial Rounded MT Bold', 'Arial Unicode MS', 'Avenir', 'Avenir Next', 'Avenir Next Condensed', 'Ayuthaya', 'Baghdad', 'Bangla MN', 'Bangla Sangam MN', 'Baskerville', 'Beirut', 'Big Caslon', 'Bodoni 72', 'Bodoni 72 Oldstyle', 'Bodoni 72 Smallcaps', 'Bodoni Ornaments', 'Bradley Hand', 'Brush Script MT', 'Chalkboard', 'Chalkboard SE', 'Chalkduster', 'Charter', 'Cochin', 'Comic Sans MS', 'Copperplate', 'Corsiva Hebrew', 'Courier New', 'Damascus', 'DecoType Naskh', 'Devanagari MT', 'Devanagari Sangam MN', 'Didot', 'DIN Alternate', 'DIN Condensed', 'Diwan Kufi', 'Diwan Thuluth', 'Euphemia UCAS', 'Farah', 'Farisi', 'Futura', 'Galvji', 'GB18030 Bitmap', 'Geeza Pro', 'Geneva', 'Georgia', 'Gill Sans', 'Grantha Sangam MN', 'Gujarati MT', 'Gujarati Sangam MN', 'Gurmukhi MN', 'Gurmukhi MT', 'Gurmukhi Sangam MN', 'Heiti SC', 'Heiti TC', 'Helvetica', 'Helvetica Neue', 'Herculanum', 'Hiragino Maru Gothic ProN', 'Hiragino Mincho ProN', 'Hiragino Sans', 'Hiragino Sans GB', 'Hoefler Text', 'Impact', 'InaiMathi', 'ITF Devanagari', 'ITF Devanagari Marathi', 'Kailasa', 'Kannada MN', 'Kannada Sangam MN', 'Kefa', 'Khmer MN', 'Khmer Sangam MN', 'Kohinoor Bangla', 'Kohinoor Devanagari', 'Kohinoor Gujarati', 'Kohinoor Telugu', 'Kokonor', 'Krungthep', 'KufiStandardGK', 'Lao MN', 'Lao Sangam MN', 'Lucida Grande', 'Luminari', 'Malayalam MN', 'Malayalam Sangam MN', 'Marker Felt', 'Menlo', 'Microsoft Sans Serif', 'Mishafi', 'Mishafi Gold', 'Monaco', 'Mshtakan', 'Mukta Mahee', 'Muna', 'Myanmar MN', 'Myanmar Sangam MN', 'Nadeem', 'New Peninim MT', 'Noteworthy', 'Noto Nastaliq Urdu', 'Noto Sans Kannada', 'Noto Sans Myanmar', 'Noto Sans Oriya', 'Noto Serif Myanmar', 'Optima', 'Oriya MN', 'Oriya Sangam MN', 'Palatino', 'Papyrus', 'Party LET', 'Phosphate', 'PingFang HK', 'PingFang SC', 'PingFang TC', 'Plantagenet Cherokee', 'PT Mono', 'PT Sans', 'PT Sans Caption', 'PT Sans Narrow', 'PT Serif', 'PT Serif Caption', 'Raanana', 'Rockwell', 'Sana', 'Sathu', 'Savoye LET', 'Shree Devanagari 714', 'SignPainter', 'Silom', 'Sinhala MN', 'Sinhala Sangam MN', 'Skia', 'Snell Roundhand', 'Songti SC', 'Songti TC', 'STIX Two Math', 'STIX Two Text', 'STSong', 'Sukhumvit Set', 'Symbol', 'Tahoma', 'Tamil MN', 'Tamil Sangam MN', 'Telugu MN', 'Telugu Sangam MN', 'Thonburi', 'Times New Roman', 'Trattatello', 'Trebuchet MS', 'Verdana', 'Waseem', 'Webdings', 'Wingdings', 'Wingdings 2', 'Wingdings 3', 'Zapf Dingbats', 'Zapfino']\n"
     ]
    }
   ],
   "source": [
    "from PyQt5.QtGui import QFontDatabase\n",
    "\n",
    "print(QFontDatabase().families())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
