{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI2\n",
    "updates\n",
    "1. pick labels\n",
    "2. change prob acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick the labels that you want to use here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_labels = [\"door_nock\",\"glass_shatter\",\"car_horn\",\"dog_bark\",\"drilling\",\"nothing\",\"siren\",\"nothing2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sound_rate (only raspberrypi use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = '''pcm.!default {\n",
    "#     type asym\n",
    "#     capture.pcm \"mic\"\n",
    "#     playback.pcm \"speaker\"\n",
    "# }\n",
    "# pcm.mic {\n",
    "#     type plug\n",
    "#     slave {\n",
    "#         pcm \"hw:2,0\"\n",
    "#     }\n",
    "# }\n",
    "# pcm.speaker {\n",
    "#     type plug\n",
    "#     slave {\n",
    "#         pcm \"hw:1,0\"\n",
    "#     }\n",
    "# }'''\n",
    "\n",
    "# # 파일 경로와 이름 설정\n",
    "# file_path = \"/home/pi/.asoundrc\"\n",
    "\n",
    "# # 텍스트 파일 생성 및 저장\n",
    "# with open(file_path, \"w\") as file:\n",
    "#     file.write(text)\n",
    "\n",
    "# print(\"Text saved to:\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 경로: c:\\Users\\오태호\\Documents\\GitHub\\DUNE\\Savin_code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "print(\"현재 경로:\", current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to the model: c:\\Users\\오태호\\Documents\\GitHub\\DUNE\\Savin_code\\../@AI/Sound Classification/ResNet18_02.pth\n"
     ]
    }
   ],
   "source": [
    "# Relative path to the model file\n",
    "relative_path_to_model = \"../@AI/Sound Classification/ResNet18_02.pth\"\n",
    "\n",
    "# Combine the current path and the relative path to create the absolute path to the model\n",
    "path_to_model = os.path.join(current_path, relative_path_to_model)\n",
    "\n",
    "print(\"Path to the model:\", path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded deivce :  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\homeyyj\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Anaconda\\envs\\homeyyj\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#One GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(512, len(selected_labels))\n",
    "try:\n",
    "    state_dict = torch.load(path_to_model, map_location=device)\n",
    "    new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    print(\"Model successfully loaded deivce : \",device)\n",
    "except:\n",
    "    print(\"Failed to load the model. Please check the model file.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\homeyyj\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "c:\\Anaconda\\envs\\homeyyj\\lib\\site-packages\\torchaudio\\functional\\functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from torchvision import transforms  # Import the transforms module\n",
    "\n",
    "\n",
    "#Transform\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "class MonoToColor(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(MonoToColor, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.repeat(self.num_channels, 1, 1)\n",
    "\n",
    "# Apply the same transformation as used during training\n",
    "transformation = transforms.Compose([\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=128),\n",
    "    torchaudio.transforms.AmplitudeToDB(stype='power', top_db=80),\n",
    "    MonoToColor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech to text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import speech_recognition as sr\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read audio func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio():\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=pyaudio.paInt16, channels=1, rate=16000, frames_per_buffer=1024, input=True)\n",
    "    frames = []\n",
    "    for i in range(0, int(16000 / 1024 * 3)):\n",
    "        data = stream.read(1024)\n",
    "        frames.append(data)\n",
    "    stream.close()\n",
    "    audio.terminate()  # close the PyAudio object\n",
    "    return b''.join(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio_data = sr.AudioData(audio, 16000, 2)\n",
    "    try:\n",
    "        text = recognizer.recognize_sphinx(audio_data)\n",
    "        \n",
    "        return text\n",
    "    except:\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spinx Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(times):\n",
    "    for i in range(0, times):\n",
    "        audio = record_audio()\n",
    "        text = transcribe_audio(audio)\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMES = 0\n",
    "if __name__ == \"__main__\":\n",
    "    main(TIMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOUND EFFECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cpu\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "import sounddevice as sd\n",
    "\n",
    "print(\"device : \",device)\n",
    "## print every labels\n",
    "def continuous_sound_prediction(model, device, transformation, sample_rate, target_sample_rate):\n",
    "    # Define class labels\n",
    "\n",
    "    # Record a 2 seconds mono audio at the specified sample rate\n",
    "    duration = 2.0  # seconds\n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1) \n",
    "    sd.wait()\n",
    "\n",
    "    # Convert to PyTorch tensor and switch channels and frames\n",
    "    recording = torch.from_numpy(recording).float()\n",
    "    recording = torch.transpose(recording, 0, 1)\n",
    "\n",
    "    # Resample if necessary\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(sample_rate, target_sample_rate)\n",
    "        recording = resampler(recording)\n",
    "\n",
    "    # Mix down if necessary\n",
    "    if recording.shape[0] > 1:\n",
    "        recording = torch.mean(recording, dim=0, keepdim=True)\n",
    "\n",
    "    # Cut or pad if necessary\n",
    "    if recording.shape[1] > target_sample_rate:\n",
    "        recording = recording[:, :target_sample_rate]\n",
    "    elif recording.shape[1] < target_sample_rate:\n",
    "        num_missing_samples = target_sample_rate - recording.shape[1]\n",
    "        last_dim_padding = (0, num_missing_samples)\n",
    "        recording = nn.functional.pad(recording, last_dim_padding)\n",
    "\n",
    "    # Apply transformation\n",
    "    recording = transformation(recording)\n",
    "\n",
    "    # Make the prediction\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():  # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "        recording = recording.to(device)\n",
    "        outputs = model(recording[None, ...])\n",
    "        #probabilities = F.softmax(outputs, dim=1)  # apply softmax to output (for 100%)\n",
    "        #_, predicted = torch.max(outputs, 1)\n",
    "        probabilities = torch.sigmoid(outputs)  # apply sigmoid to output (for indivisual points)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Get predicted label and its corresponding probability\n",
    "    predicted_label = selected_labels[predicted.item()]\n",
    "    predicted_confidence = probabilities[0, predicted.item()].item()  # get the probability of the predicted class\n",
    "\n",
    "    ######## Adjust 'x' probability   #########\n",
    "    change_label = \"glass_shatter\"\n",
    "    change_probability = 0.5\n",
    "    try:# if you have something to reduce\n",
    "        x_index = selected_labels.index(change_label)\n",
    "        probabilities[0, x_index] = max(0.0, probabilities[0, x_index].item() - change_probability)\n",
    "    except:#if you dont\n",
    "        pass\n",
    "    # Print the probabilities of all labels in one line\n",
    "    #prob_strs = [f\"{label} {probabilities[0, idx].item():.2%}\" for idx, label in enumerate(selected_labels)]\n",
    "    #print(f\"/ \".join(prob_strs))\n",
    "\n",
    "    if predicted_confidence > 0.0:\n",
    "        return predicted_label, predicted_confidence, probabilities\n",
    "    else:\n",
    "        return \"NONE\" , 0 , \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 결과 값 : \n",
      "RPi.GPIO import failed. No vibration\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'VibrationController' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 261\u001b[0m\n\u001b[0;32m    258\u001b[0m MainWindow \u001b[39m=\u001b[39m QtWidgets\u001b[39m.\u001b[39mQMainWindow()\n\u001b[0;32m    260\u001b[0m ui \u001b[39m=\u001b[39m Ui_MainWindow()\n\u001b[1;32m--> 261\u001b[0m ui\u001b[39m.\u001b[39;49msetupUi(MainWindow)\n\u001b[0;32m    263\u001b[0m MainWindow\u001b[39m.\u001b[39mshow()\n\u001b[0;32m    264\u001b[0m sys\u001b[39m.\u001b[39mexit(app\u001b[39m.\u001b[39mexec_())\n",
      "Cell \u001b[1;32mIn[13], line 158\u001b[0m, in \u001b[0;36mUi_MainWindow.setupUi\u001b[1;34m(self, MainWindow)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msound_analysis\u001b[39m.\u001b[39mresult_signal\u001b[39m.\u001b[39mconnect(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdateLabel)\n\u001b[0;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msound_analysis\u001b[39m.\u001b[39mresult_signal\u001b[39m.\u001b[39mconnect(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdateLabel2)\n\u001b[1;32m--> 158\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msound_analysis\u001b[39m.\u001b[39;49minitialize_vibration_controller()  \u001b[39m# Initialize vibration controller\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msound_analysis\u001b[39m.\u001b[39mstart()  \u001b[39m# Start the sound analysis thread\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_new_labels_visible \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 43\u001b[0m, in \u001b[0;36mSoundAnalysis.initialize_vibration_controller\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minitialize_vibration_controller\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvibration_controller \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvibration_controller \u001b[39m=\u001b[39m VibrationController()\n\u001b[0;32m     44\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m             vibration_thread \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mThread(target\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvibration_controller\u001b[39m.\u001b[39minitialize_pwm)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VibrationController' is not defined"
     ]
    }
   ],
   "source": [
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from PyQt5.QtCore import QThread, pyqtSignal\n",
    "from PyQt5.QtGui import QMovie\n",
    "\n",
    "from time import sleep\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyaudio\n",
    "import torchaudio\n",
    "import sounddevice as sd\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "###### INIT ######\n",
    "p = pyaudio.PyAudio()\n",
    "sample_rate = SAMPLE_RATE\n",
    "target_sample_rate = SAMPLE_RATE\n",
    "mode = 0\n",
    "print(\" 결과 값 : \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sound Analysis class running on a separate thread\n",
    "class SoundAnalysis(QThread):\n",
    "    # Define a pyqtSignal with str type, which will be used to send the analysis results to the main thread\n",
    "    result_signal = pyqtSignal(str, float)  # Add a float type for the probability\n",
    "\n",
    "    def __init__(self, model, device, transformation, sample_rate):\n",
    "        QThread.__init__(self)\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.transformation = transformation\n",
    "        self.sample_rate = sample_rate\n",
    "        self.vibration_on = False\n",
    "        self.vibration_controller = None \n",
    "\n",
    "    def initialize_vibration_controller(self):\n",
    "        if self.vibration_controller is None:\n",
    "            self.vibration_controller = VibrationController()\n",
    "            try:\n",
    "                vibration_thread = threading.Thread(target=self.vibration_controller.initialize_pwm)\n",
    "                vibration_thread.start()\n",
    "            except:\n",
    "                print(\"Vibration initialization failed\")\n",
    "        \n",
    "\n",
    "    def run(self):## Main code\n",
    "        count = 0\n",
    "        text_str = \"\"\n",
    "        vibration_triggered = False  # Flag to prevent continuous triggering\n",
    "        while True:\n",
    "            if mode == True:\n",
    "                text_str = \"\"  # empty the text strings\n",
    "\n",
    "                predicted_label, predicted_confidence, probabilities = continuous_sound_prediction(\n",
    "                    model, device, transformation, SAMPLE_RATE, SAMPLE_RATE)\n",
    "                if mode == True:\n",
    "                    try:\n",
    "                        self.result_signal.emit(predicted_label, predicted_confidence)\n",
    "                        prob_strs = [f\"{label} {probabilities[0, idx].item():.2%}\" for idx, label in\n",
    "                                     enumerate(selected_labels)]\n",
    "\n",
    "                        if predicted_confidence >= 0.95 and not vibration_triggered:\n",
    "                            if not self.vibration_on:\n",
    "                                self.vibration_on = True\n",
    "                                self.vibration_controller.start_vibration()\n",
    "                                vibration_triggered = True  # Set the flag to True\n",
    "                        else:\n",
    "                            if self.vibration_on and vibration_triggered:\n",
    "                                self.vibration_on = False\n",
    "                                self.vibration_controller.stop_vibration()\n",
    "                                vibration_triggered = False  # Reset the flag to False\n",
    "\n",
    "                        print(f\"\\r{count} / \" + \" / \".join(prob_strs), end=\"\")\n",
    "                    except:\n",
    "                        self.result_signal.emit(predicted_label, predicted_confidence)\n",
    "                    count = count + 1\n",
    "            if mode == False:\n",
    "                times = 2\n",
    "                for _ in range(0, times):\n",
    "                    audio = record_audio()\n",
    "                    text = transcribe_audio(audio)\n",
    "                    if text is not None:  # Check if text is not None before appending\n",
    "                        text_str += text + \" \"\n",
    "                    if mode == True:\n",
    "                        break\n",
    "                    self.result_signal.emit(text_str, 0)\n",
    "        \n",
    "    def reset_label(self):# Restting the labels when the button is pressed\n",
    "        self.result_signal.emit(\"켜는중\", 0)\n",
    "        if self.vibration_controller.switch_pressed():  # 스위치가 눌렸는지 확인\n",
    "            self.vibration_controller.stop_vibration()  # 진동 멈춤\n",
    "\n",
    "class Ui_MainWindow(object):\n",
    "    def setupUi(self, MainWindow):\n",
    "        MainWindow.setObjectName(\"MainWindow\")\n",
    "        MainWindow.resize(640, 480)\n",
    "        self.received_text = \"\"\n",
    "        self.centralwidget = QtWidgets.QWidget(MainWindow)\n",
    "        self.centralwidget.setObjectName(\"centralwidget\")\n",
    "        self.label = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.label.setGeometry(QtCore.QRect(40, 300, 561, 91))\n",
    "        self.label.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.label.setObjectName(\"text_label\")\n",
    "        self.label.setWordWrap(True) # 자동 줄바꿈\n",
    "\n",
    "\n",
    "        self.label_2 = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.label_2.setGeometry(QtCore.QRect(40, 30, 381, 211))\n",
    "        self.label_2.setText(\"\")\n",
    "        self.label_2.setObjectName(\"imgae_image\")\n",
    "\n",
    "        self.pushButton = QtWidgets.QPushButton(self.centralwidget)\n",
    "        self.pushButton.setGeometry(QtCore.QRect(470, 40, 141, 101))\n",
    "        self.pushButton.setObjectName(\"pushButton\")\n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "\n",
    "        #english_text_label\n",
    "        self.new_label = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.new_label.setGeometry(QtCore.QRect(40, 200, 561, 201))\n",
    "        self.new_label.setText(\"\")\n",
    "        self.new_label.setAlignment(QtCore.Qt.AlignCenter)#텍스트 중앙 정렬\n",
    "        self.new_label.setObjectName(\"english_text_label\")\n",
    "        self.new_label.hide()  # Hide the new label initially\n",
    "        #english_image_label\n",
    "        self.new_label_2 = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.new_label_2.setGeometry(QtCore.QRect(50, 40, 144, 130))\n",
    "        self.new_label_2.setPixmap(QtGui.QPixmap(\"english_image.png\"))\n",
    "        self.new_label_2.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.new_label_2.setObjectName(\"english_image_label\")\n",
    "        self.new_label_2.hide()  # Hide the new label initially\n",
    "\n",
    "       \n",
    "\n",
    "       \n",
    "        \n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "        self.menubar = QtWidgets.QMenuBar(MainWindow)\n",
    "        self.menubar.setGeometry(QtCore.QRect(0, 0, 800, 29))\n",
    "        self.menubar.setObjectName(\"menubar\")\n",
    "        MainWindow.setMenuBar(self.menubar)\n",
    "        self.statusbar = QtWidgets.QStatusBar(MainWindow)\n",
    "        self.statusbar.setObjectName(\"statusbar\")\n",
    "        MainWindow.setStatusBar(self.statusbar)\n",
    "\n",
    "        self.retranslateUi(MainWindow)\n",
    "        QtCore.QMetaObject.connectSlotsByName(MainWindow)\n",
    "\n",
    "        self.pushButton.clicked.connect(self.onPushButtonClicked)\n",
    "\n",
    "        self.sound_analysis = SoundAnalysis(model, device, transformation, SAMPLE_RATE)\n",
    "        self.sound_analysis.result_signal.connect(self.updateLabel)\n",
    "        self.sound_analysis.result_signal.connect(self.updateLabel2)\n",
    "        self.sound_analysis.initialize_vibration_controller()  # Initialize vibration controller\n",
    "        self.sound_analysis.start()  # Start the sound analysis thread\n",
    "        \n",
    "        self.is_new_labels_visible = False\n",
    "        \n",
    "\n",
    "    def onPushButtonClicked(self): ######BUTTON#######\n",
    "        global mode\n",
    "        mode = not mode\n",
    "        self.sound_analysis.reset_label()#reset the screen (its connected to the sound analysis class)\n",
    "        print(\"mode now :  \",mode)\n",
    "\n",
    "    def updateLabel(self, predicted_label, predicted_confidence):\n",
    "        #print(\"Received signal\")  # Print message when signal is received\n",
    "        if predicted_confidence == 0:\n",
    "            self.label.setText(f\"{predicted_label}\")\n",
    "        else:\n",
    "            self.label.setText(f\"{predicted_label}  {predicted_confidence*100:.2f}%\")\n",
    "        #print(predicted_label)\n",
    "        \n",
    "        \n",
    "    def updateLabel2(self, predicted_label):\n",
    "        relative_image_folder_path = \"../png\" #\\ only works for windows\n",
    "        image_folder_path= os.path.join(current_path, relative_image_folder_path)\n",
    "        full_file_name = os.path.join(image_folder_path, f\"{predicted_label}.png\")\n",
    "        #self.movie = QMovie(full_file_name)\n",
    "        #self.label.setMovie(self.movie)\n",
    "        #self.movie.start()\n",
    "        self.label_2.setPixmap(QtGui.QPixmap(full_file_name)) \n",
    "        #print(predicted_label)\n",
    "\n",
    "\n",
    "    def retranslateUi(self, MainWindow):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        MainWindow.setWindowTitle(_translate(\"MainWindow\", \"MainWindow\"))\n",
    "        self.label.setFont(QtGui.QFont(\"AppleSystemUIFont\",20))\n",
    "        self.label.setStyleSheet(\"Color : black\")\n",
    "        self.pushButton.setText(_translate(\"MainWindow\", \"PushButton\"))\n",
    "        \n",
    "try:\n",
    "    import RPi.GPIO as GPIO\n",
    "    print(\"RPi.GPIO loaded successfully\")\n",
    "    import threading\n",
    "    print(\"threading loaded successfully\")\n",
    "\n",
    "    class VibrationController:\n",
    "        def __init__(self):\n",
    "            # 핀 번호 설정\n",
    "            self.red_button_pin = 17  # 스위치 핀\n",
    "            self.vibration_motor_pin = 18  # 진동 모듈 핀\n",
    "            \n",
    "            # 진동 세기 초기화\n",
    "            self.vibration_intensity_temp = 100\n",
    "            self.vibration_intensity = 0\n",
    "            \n",
    "            # 이전 스위치 상태 초기화\n",
    "            self.prev_red_button_state = GPIO.HIGH\n",
    "            \n",
    "            self.debounce_time = 0.2\n",
    "            \n",
    "            # 진동 상태를 저장하는 변수\n",
    "            self.vibration_on = False\n",
    "            \n",
    "            # GPIO 초기화\n",
    "            GPIO.setmode(GPIO.BCM)\n",
    "            GPIO.setup(self.red_button_pin, GPIO.IN, pull_up_down=GPIO.PUD_UP)\n",
    "            GPIO.setup(self.vibration_motor_pin, GPIO.OUT)\n",
    "\n",
    "            self.pwm_frequency = 1000\n",
    "            self.pwm = None \n",
    "            \n",
    "        def initialize_pwm(self):\n",
    "            if self.pwm is None:\n",
    "                self.pwm = GPIO.PWM(self.vibration_motor_pin, self.pwm_frequency)\n",
    "                self.pwm.start(self.vibration_intensity)\n",
    "        \n",
    "        def start_vibration(self):\n",
    "            self.initialize_pwm()\n",
    "            self.vibration_intensity = self.vibration_intensity_temp\n",
    "            self.pwm.ChangeDutyCycle(self.vibration_intensity)\n",
    "            self.display_vibration_intensity()\n",
    "        \n",
    "        def stop_vibration(self):\n",
    "            self.initialize_pwm()\n",
    "            self.vibration_intensity_temp = self.vibration_intensity\n",
    "            self.vibration_intensity = 0\n",
    "            self.pwm.ChangeDutyCycle(self.vibration_intensity)\n",
    "            self.display_vibration_intensity()\n",
    "        \n",
    "        def display_vibration_intensity(self):\n",
    "            print(f\"진동 세기: {self.vibration_intensity}\")\n",
    "\n",
    "        def switch_pressed(self):\n",
    "            return GPIO.input(self.red_button_pin) == GPIO.LOW\n",
    "except:\n",
    "    print(\"RPi.GPIO import failed. No vibration\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    MainWindow = QtWidgets.QMainWindow()\n",
    "\n",
    "    ui = Ui_MainWindow()\n",
    "    ui.setupUi(MainWindow)\n",
    "\n",
    "    MainWindow.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가능한 폰트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtGui import QFontDatabase\n",
    "\n",
    "print(QFontDatabase().families())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
