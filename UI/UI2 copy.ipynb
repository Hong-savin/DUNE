{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI2\n",
    "updates\n",
    "1. pick labels\n",
    "2. change prob acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick the labels that you want to use here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 / door_nock 51.71% / glass_shatter 31.24% / car_horn 1.46% / dog_bark 99.11% / drilling 0.52% / nothing 4.60% / siren 2.03% / nothing2 1.66%"
     ]
    }
   ],
   "source": [
    "selected_labels = [\"door_nock\",\"glass_shatter\",\"car_horn\",\"dog_bark\",\"drilling\",\"nothing\",\"siren\",\"nothing2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 경로: c:\\Users\\homey\\Documents\\GitHub\\DUNE\\UI\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "print(\"현재 경로:\", current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to the model: c:\\Users\\homey\\Documents\\GitHub\\DUNE\\UI\\../@AI/Sound Classification/ResNet18_02.pth\n"
     ]
    }
   ],
   "source": [
    "# Relative path to the model file\n",
    "relative_path_to_model = \"../@AI/Sound Classification/ResNet18_02.pth\"\n",
    "\n",
    "# Combine the current path and the relative path to create the absolute path to the model\n",
    "path_to_model = os.path.join(current_path, relative_path_to_model)\n",
    "\n",
    "print(\"Path to the model:\", path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded deivce :  cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#One GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(512, len(selected_labels))\n",
    "try:\n",
    "    state_dict = torch.load(path_to_model, map_location=device)\n",
    "    new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    print(\"Model successfully loaded deivce : \",device)\n",
    "except:\n",
    "    print(\"Failed to load the model. Please check the model file.\")\n",
    "    print(\"a\")#this is here just to cause an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from torchvision import transforms  # Import the transforms module\n",
    "\n",
    "\n",
    "#Transform\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "class MonoToColor(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(MonoToColor, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.repeat(self.num_channels, 1, 1)\n",
    "\n",
    "# Apply the same transformation as used during training\n",
    "transformation = transforms.Compose([\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=128),\n",
    "    torchaudio.transforms.AmplitudeToDB(stype='power', top_db=80),\n",
    "    MonoToColor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cpu\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "import sounddevice as sd\n",
    "\n",
    "print(\"device : \",device)\n",
    "## print every labels\n",
    "def continuous_sound_prediction(model, device, transformation, sample_rate, target_sample_rate):\n",
    "    # Define class labels\n",
    "\n",
    "    # Record a 2 seconds mono audio at the specified sample rate\n",
    "    duration = 2.0  # seconds\n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1) \n",
    "    sd.wait()\n",
    "\n",
    "    # Convert to PyTorch tensor and switch channels and frames\n",
    "    recording = torch.from_numpy(recording).float()\n",
    "    recording = torch.transpose(recording, 0, 1)\n",
    "\n",
    "    # Resample if necessary\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(sample_rate, target_sample_rate)\n",
    "        recording = resampler(recording)\n",
    "\n",
    "    # Mix down if necessary\n",
    "    if recording.shape[0] > 1:\n",
    "        recording = torch.mean(recording, dim=0, keepdim=True)\n",
    "\n",
    "    # Cut or pad if necessary\n",
    "    if recording.shape[1] > target_sample_rate:\n",
    "        recording = recording[:, :target_sample_rate]\n",
    "    elif recording.shape[1] < target_sample_rate:\n",
    "        num_missing_samples = target_sample_rate - recording.shape[1]\n",
    "        last_dim_padding = (0, num_missing_samples)\n",
    "        recording = nn.functional.pad(recording, last_dim_padding)\n",
    "\n",
    "    # Apply transformation\n",
    "    recording = transformation(recording)\n",
    "\n",
    "    # Make the prediction\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():  # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "        recording = recording.to(device)\n",
    "        outputs = model(recording[None, ...])\n",
    "        #probabilities = F.softmax(outputs, dim=1)  # apply softmax to output (for 100%)\n",
    "        #_, predicted = torch.max(outputs, 1)\n",
    "        probabilities = torch.sigmoid(outputs)  # apply sigmoid to output (for indivisual points)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Get predicted label and its corresponding probability\n",
    "    predicted_label = selected_labels[predicted.item()]\n",
    "    predicted_confidence = probabilities[0, predicted.item()].item()  # get the probability of the predicted class\n",
    "\n",
    "    ######## Adjust 'x' probability   #########\n",
    "    change_label = \"glass_shatter\"\n",
    "    change_probability = 0.5\n",
    "    try:# if you have something to reduce\n",
    "        x_index = selected_labels.index(change_label)\n",
    "        probabilities[0, x_index] = max(0.0, probabilities[0, x_index].item() - change_probability)\n",
    "    except:#if you dont\n",
    "        pass\n",
    "    # Print the probabilities of all labels in one line\n",
    "    #prob_strs = [f\"{label} {probabilities[0, idx].item():.2%}\" for idx, label in enumerate(selected_labels)]\n",
    "    #print(f\"/ \".join(prob_strs))\n",
    "\n",
    "\n",
    "    return predicted_label, predicted_confidence, probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvisoin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msounddevice\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msd\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvisoin\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m resnet18\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m \u001b[39mimport\u001b[39;00m Variable\n\u001b[0;32m     13\u001b[0m sample_rate \u001b[39m=\u001b[39m SAMPLE_RATE\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvisoin'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172 / door_nock 24.36% / glass_shatter 25.23% / car_horn 0.14% / dog_bark 96.46% / drilling 3.39% / nothing 1.87% / siren 2.76% / nothing2 52.17%"
     ]
    }
   ],
   "source": [
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from PyQt5.QtCore import QThread, pyqtSignal\n",
    "from PyQt5.QtGui import QMovie\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import sounddevice as sd\n",
    "import torchvision.transforms as transforms\n",
    "from torchvisoin.models import resnet18\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "sample_rate = SAMPLE_RATE\n",
    "target_sample_rate = SAMPLE_RATE\n",
    "\n",
    "print(\" 결과 값 : \")\n",
    "\n",
    "# Sound Analysis class running on a separate thread\n",
    "class SoundAnalysis(QThread):\n",
    "    # Define a pyqtSignal with str type, which will be used to send the analysis results to the main thread\n",
    "    result_signal = pyqtSignal(str, float)  # Add a float type for the probability\n",
    "\n",
    "    def __init__(self, model, device, transformation, sample_rate):\n",
    "        QThread.__init__(self)\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.transformation = transformation\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    def run(self):\n",
    "        count = 0\n",
    "        while True:\n",
    "            predicted_label, predicted_confidence, probabilities = continuous_sound_prediction(model, device, transformation, SAMPLE_RATE, SAMPLE_RATE)                \n",
    "            self.result_signal.emit(predicted_label, predicted_confidence)\n",
    "            prob_strs = [f\"{label} {probabilities[0, idx].item():.2%}\" for idx, label in enumerate(selected_labels)]\n",
    "            print(f\"\\r{count} / \" + \" / \".join(prob_strs), end=\"\")\n",
    "            count = count + 1\n",
    "\n",
    "\n",
    "class Ui_MainWindow(object):\n",
    "    def setupUi(self, MainWindow):\n",
    "        MainWindow.setObjectName(\"MainWindow\")\n",
    "        MainWindow.resize(1036, 702)\n",
    "        self.received_text = \"\"\n",
    "        self.centralwidget = QtWidgets.QWidget(MainWindow)\n",
    "        self.centralwidget.setObjectName(\"centralwidget\")\n",
    "        self.label = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.label.setGeometry(QtCore.QRect(30, 430, 971, 211))\n",
    "        self.label.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.label.setObjectName(\"label\")\n",
    "\n",
    "        self.label_2 = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.label_2.setGeometry(QtCore.QRect(30, 60, 971, 351))\n",
    "        self.label_2.setText(\"\")\n",
    "        self.label_2.setObjectName(\"image\")\n",
    "        \n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "        self.menubar = QtWidgets.QMenuBar(MainWindow)\n",
    "        self.menubar.setGeometry(QtCore.QRect(0, 0, 800, 29))\n",
    "        self.menubar.setObjectName(\"menubar\")\n",
    "        MainWindow.setMenuBar(self.menubar)\n",
    "        self.statusbar = QtWidgets.QStatusBar(MainWindow)\n",
    "        self.statusbar.setObjectName(\"statusbar\")\n",
    "        MainWindow.setStatusBar(self.statusbar)\n",
    "\n",
    "        self.retranslateUi(MainWindow)\n",
    "        QtCore.QMetaObject.connectSlotsByName(MainWindow)\n",
    "\n",
    "        # Initialize SoundAnalysis and connect the result_signal with the updateLabel function\n",
    "        self.sound_analysis = SoundAnalysis(model, device, transformation, SAMPLE_RATE)\n",
    "        self.sound_analysis.result_signal.connect(self.updateLabel)\n",
    "        self.sound_analysis.result_signal.connect(self.updateLabel2)\n",
    "        self.sound_analysis.start()  # Start the sound analysis thread\n",
    "        \n",
    "    def updateLabel2(self, predicted_label):\n",
    "        relative_image_folder_path = \"../image_file\" #\\ only works for windows\n",
    "        image_folder_path= os.path.join(current_path, relative_image_folder_path)\n",
    "        full_file_name = os.path.join(image_folder_path, f\"{predicted_label}.gif\")\n",
    "        self.movie = QMovie(full_file_name)\n",
    "        self.label.setMovie(self.movie)\n",
    "        self.movie.start()\n",
    "        #self.label_2.setPixmap(QtGui.QPixmap(full_file_name))  \n",
    "        #print(predicted_label)\n",
    "\n",
    "    def updateLabel(self, predicted_label, predicted_confidence):\n",
    "        #print(\"Received signal\")  # Print message when signal is received\n",
    "        self.label.setText(f\"{predicted_label}  {predicted_confidence*100:.2f}%\")\n",
    "        #print(predicted_label)\n",
    "\n",
    "\n",
    "    def retranslateUi(self, MainWindow):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        MainWindow.setWindowTitle(_translate(\"MainWindow\", \"MainWindow\"))\n",
    "        self.label.setFont(QtGui.QFont(\"AppleSystemUIFont\",20))\n",
    "        self.label.setStyleSheet(\"Color : black\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    MainWindow = QtWidgets.QMainWindow()\n",
    "    ui = Ui_MainWindow()\n",
    "    ui.setupUi(MainWindow)\n",
    "    MainWindow.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가능한 폰트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Agency FB', 'Algerian', 'Arial', 'Arial Black', 'Arial Narrow', 'Arial Rounded MT Bold', 'Bahnschrift', 'Bahnschrift Condensed', 'Bahnschrift Light', 'Bahnschrift Light Condensed', 'Bahnschrift Light SemiCondensed', 'Bahnschrift SemiBold', 'Bahnschrift SemiBold Condensed', 'Bahnschrift SemiBold SemiConden', 'Bahnschrift SemiCondensed', 'Bahnschrift SemiLight', 'Bahnschrift SemiLight Condensed', 'Bahnschrift SemiLight SemiConde', 'Baskerville Old Face', 'Bauhaus 93', 'Bell MT', 'Berlin Sans FB', 'Berlin Sans FB Demi', 'Bernard MT Condensed', 'Blackadder ITC', 'Bodoni MT', 'Bodoni MT Black', 'Bodoni MT Condensed', 'Bodoni MT Poster Compressed', 'Book Antiqua', 'Bookman Old Style', 'Bookshelf Symbol 7', 'Bradley Hand ITC', 'Britannic Bold', 'Broadway', 'Brush Script MT', 'Calibri', 'Calibri Light', 'Californian FB', 'Calisto MT', 'Cambria', 'Cambria Math', 'Candara', 'Candara Light', 'Cascadia Code', 'Cascadia Code ExtraLight', 'Cascadia Code Light', 'Cascadia Code SemiBold', 'Cascadia Code SemiLight', 'Cascadia Mono', 'Cascadia Mono ExtraLight', 'Cascadia Mono Light', 'Cascadia Mono SemiBold', 'Cascadia Mono SemiLight', 'Castellar', 'Centaur', 'Century', 'Century Gothic', 'Century Schoolbook', 'Chiller', 'Colonna MT', 'Comic Sans MS', 'Consolas', 'Constantia', 'Cooper Black', 'Copperplate Gothic Bold', 'Copperplate Gothic Light', 'Corbel', 'Corbel Light', 'Courier', 'Courier New', 'Curlz MT', 'Dubai', 'Dubai Light', 'Dubai Medium', 'Ebrima', 'Edwardian Script ITC', 'Elephant', 'Engravers MT', 'Eras Bold ITC', 'Eras Demi ITC', 'Eras Light ITC', 'Eras Medium ITC', 'Felix Titling', 'Fixedsys', 'Footlight MT Light', 'Forte', 'Franklin Gothic Book', 'Franklin Gothic Demi', 'Franklin Gothic Demi Cond', 'Franklin Gothic Heavy', 'Franklin Gothic Medium', 'Franklin Gothic Medium Cond', 'Freestyle Script', 'French Script MT', 'FZShuTi', 'FZYaoTi', 'Gabriola', 'Gadugi', 'Garamond', 'Georgia', 'Gigi', 'Gill Sans MT', 'Gill Sans MT Condensed', 'Gill Sans MT Ext Condensed Bold', 'Gill Sans Ultra Bold', 'Gill Sans Ultra Bold Condensed', 'Gloucester MT Extra Condensed', 'Goudy Old Style', 'Goudy Stout', 'Haan Wing2', 'Haettenschweiler', 'Han Santteut Dotum', 'Hancom Gothic', 'Hancom MalangMalang', 'HancomEQN', 'Harlow Solid Italic', 'Harrington', 'High Tower Text', 'HoloLens MDL2 Assets', 'HyhwpEQ', 'HY견고딕', 'HY견명조', 'HY궁서B', 'HY그래픽M', 'HY목각파임B', 'HY신명조', 'HY얕은샘물M', 'HY엽서L', 'HY엽서M', 'HY중고딕', 'HY헤드라인M', 'Impact', 'Imprint MT Shadow', 'Informal Roman', 'Ink Free', 'Javanese Text', 'Jokerman', 'Juice ITC', 'Kristen ITC', 'Kunstler Script', 'Leelawadee UI', 'Leelawadee UI Semilight', 'LiSu', 'Lucida Bright', 'Lucida Calligraphy', 'Lucida Console', 'Lucida Fax', 'Lucida Handwriting', 'Lucida Sans', 'Lucida Sans Typewriter', 'Lucida Sans Unicode', 'Magneto', 'Maiandra GD', 'Malgun Gothic', 'Marlett', 'Matura MT Script Capitals', 'Microsoft Himalaya', 'Microsoft JhengHei', 'Microsoft JhengHei Light', 'Microsoft JhengHei UI', 'Microsoft JhengHei UI Light', 'Microsoft New Tai Lue', 'Microsoft PhagsPa', 'Microsoft Sans Serif', 'Microsoft Tai Le', 'Microsoft YaHei', 'Microsoft YaHei Light', 'Microsoft YaHei UI', 'Microsoft YaHei UI Light', 'Microsoft Yi Baiti', 'MingLiU-ExtB', 'MingLiU_HKSCS-ExtB', 'Mistral', 'Modern', 'Modern No. 20', 'Mongolian Baiti', 'Monotype Corsiva', 'MS Gothic', 'MS Outlook', 'MS PGothic', 'MS Reference Sans Serif', 'MS Reference Specialty', 'MS Sans Serif', 'MS Serif', 'MS UI Gothic', 'MT Extra', 'MV Boli', 'Myanmar Text', 'NanumGothic', 'NewJumja', 'Niagara Engraved', 'Niagara Solid', 'Nirmala UI', 'Nirmala UI Semilight', 'NSimSun', 'OCR A Extended', 'Old English Text MT', 'Onyx', 'Palace Script MT', 'Palatino Linotype', 'Papyrus', 'Parchment', 'Perpetua', 'Perpetua Titling MT', 'Playbill', 'PMingLiU-ExtB', 'Poor Richard', 'Pristina', 'Rage Italic', 'Ravie', 'Rockwell', 'Rockwell Condensed', 'Rockwell Extra Bold', 'Roman', 'Sans Serif Collection', 'Script', 'Script MT Bold', 'Segoe Fluent Icons', 'Segoe MDL2 Assets', 'Segoe Print', 'Segoe Script', 'Segoe UI', 'Segoe UI Black', 'Segoe UI Emoji', 'Segoe UI Historic', 'Segoe UI Light', 'Segoe UI Semibold', 'Segoe UI Semilight', 'Segoe UI Symbol', 'Segoe UI Variable', 'Segoe UI Variable Display', 'Segoe UI Variable Display Light', 'Segoe UI Variable Display Semib', 'Segoe UI Variable Display Semil', 'Segoe UI Variable Small', 'Segoe UI Variable Small Light', 'Segoe UI Variable Small Semibol', 'Segoe UI Variable Small Semilig', 'Segoe UI Variable Text', 'Segoe UI Variable Text Light', 'Segoe UI Variable Text Semibold', 'Segoe UI Variable Text Semiligh', 'Showcard Gothic', 'SimSun', 'SimSun-ExtB', 'Sitka', 'Sitka Banner', 'Sitka Banner Semibold', 'Sitka Display', 'Sitka Display Semibold', 'Sitka Heading', 'Sitka Heading Semibold', 'Sitka Small', 'Sitka Small Semibold', 'Sitka Subheading', 'Sitka Subheading Semibold', 'Sitka Text', 'Sitka Text Semibold', 'Small Fonts', 'Snap ITC', 'STCaiyun', 'Stencil', 'STFangsong', 'STHupo', 'STKaiti', 'STLiti', 'STSong', 'STXihei', 'STXingkai', 'STXinwei', 'STZhongsong', 'Sylfaen', 'Symbol', 'System', 'Tahoma', 'Tempus Sans ITC', 'Terminal', 'Times New Roman', 'Trebuchet MS', 'Tw Cen MT', 'Tw Cen MT Condensed', 'Tw Cen MT Condensed Extra Bold', 'Verdana', 'Viner Hand ITC', 'Vivaldi', 'Vladimir Script', 'Webdings', 'Wide Latin', 'Wingdings', 'Wingdings 2', 'Wingdings 3', 'YouYuan', 'Yu Gothic', 'Yu Gothic Light', 'Yu Gothic Medium', 'Yu Gothic UI', 'Yu Gothic UI Light', 'Yu Gothic UI Semibold', 'Yu Gothic UI Semilight', '굴림', '굴림체', '궁서', '궁서체', '나눔고딕', '나눔고딕 ExtraBold', '돋움', '돋움체', '맑은 고딕', '맑은 고딕 Semilight', '바탕', '바탕체', '새굴림', '한컴 고딕', '한컴 말랑말랑 Bold', '한컴 말랑말랑 Regular', '한컴 훈민정음 가로쓰기', '한컴 훈민정음 세로쓰기', '한컴산뜻돋움', '함초롬돋움', '함초롬돋움 확장', '함초롬바탕', '함초롬바탕 확장', '함초롬바탕 확장B', '휴먼둥근헤드라인', '휴먼매직체', '휴먼모음T', '휴먼아미체', '휴먼엑스포', '휴먼옛체', '휴먼편지체']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 / door_nock 44.26% / glass_shatter 44.92% / car_horn 0.90% / dog_bark 88.66% / drilling 1.80% / nothing 1.02% / siren 1.55% / nothing2 20.76%"
     ]
    }
   ],
   "source": [
    "from PyQt5.QtGui import QFontDatabase\n",
    "\n",
    "print(QFontDatabase().families())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
