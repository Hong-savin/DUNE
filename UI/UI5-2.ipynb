{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI4\n",
    "updates\n",
    "1. Better Sound Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mic device pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device #1 name: 갤럭시 S2 마이크\n",
      "Device #2 name: USB PnP Sound Device\n",
      "Device #4 name: MacBook Air 마이크\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "def list_input_devices():\n",
    "    devices = sd.query_devices()\n",
    "    for i, device in enumerate(devices):\n",
    "        if device['max_input_channels'] > 0:  # this is an input device\n",
    "            print(f\"Device #{i} name: {device['name']}\")\n",
    "\n",
    "# List available input devices (including microphones)\n",
    "list_input_devices()\n",
    "device_id = 2 # <<<  -  pick your mic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mic Test\n",
    "MIC TEST type 1 if you want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|"
     ]
    }
   ],
   "source": [
    "#MIC TEST type 1 if you want to test\n",
    "test = 1\n",
    "if test == 1:\n",
    "    import numpy as np\n",
    "\n",
    "    # Choose the device to use for recording\n",
    "    duration = 2  # seconds\n",
    "\n",
    "    # Create a buffer to store the audio data\n",
    "    buffer = np.zeros((duration * 44100,))\n",
    "    buffer_index = 0\n",
    "\n",
    "    # Define a callback function to process the audio input\n",
    "    def audio_callback(indata, frames, time, status):\n",
    "        global buffer_index\n",
    "        volume_norm = np.linalg.norm(indata) * 10\n",
    "        print(f'\\r{\"|\" * int(volume_norm)}', end='')  # print a simple \"volume bar\"\n",
    "\n",
    "        # Store the incoming data in the buffer\n",
    "        buffer[buffer_index:buffer_index+frames] = indata[:, 0]\n",
    "        buffer_index += frames\n",
    "\n",
    "    # Create a stream object\n",
    "    stream = sd.InputStream(callback=audio_callback, device=device_id, channels=1, samplerate=44100)\n",
    "\n",
    "    # Start the stream\n",
    "    with stream:\n",
    "        # Record for 3 seconds\n",
    "        sd.sleep(duration * 1000)\n",
    "\n",
    "    # Play back the recorded sound\n",
    "    sd.play(buffer, samplerate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick the labels that you want to use here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sound_rate (only raspberrypi use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = '''pcm.!default {\n",
    "#     type asym\n",
    "#     capture.pcm \"mic\"\n",
    "#     playback.pcm \"speaker\"\n",
    "# }\n",
    "# pcm.mic {\n",
    "#     type plug\n",
    "#     slave {\n",
    "#         pcm \"hw:2,0\"\n",
    "#     }\n",
    "# }\n",
    "# pcm.speaker {\n",
    "#     type plug\n",
    "#     slave {\n",
    "#         pcm \"hw:1,0\"\n",
    "#     }\n",
    "# }'''\n",
    "\n",
    "# # 파일 경로와 이름 설정\n",
    "# file_path = \"/home/pi/.asoundrc\"\n",
    "\n",
    "# # 텍스트 파일 생성 및 저장\n",
    "# with open(file_path, \"w\") as file:\n",
    "#     file.write(text)\n",
    "\n",
    "# print(\"Text saved to:\", file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to the model: ../@AI/AI/models/Batch4-1k_004.pth\n"
     ]
    }
   ],
   "source": [
    "# Relative path to the model file\n",
    "path_to_model = '../@AI/AI/models/Batch4-1k_004.pth'\n",
    "print(\"Path to the model:\", path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded deivce :  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owo/anaconda3/envs/torchenv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/owo/anaconda3/envs/torchenv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#One GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(512, 14)\n",
    "try:\n",
    "    state_dict = torch.load(path_to_model, map_location=device)\n",
    "    new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    print(\"Model successfully loaded deivce : \",device)\n",
    "except:\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    print(\"Failed to load the model. Please check the model file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from torchvision import transforms  # Import the transforms module\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "# Normalize\n",
    "class MinMaxNormalize(nn.Module):\n",
    "    def __init__(self, min_val=None, max_val=None):\n",
    "        super(MinMaxNormalize, self).__init__()\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        if self.min_val is None or self.max_val is None:\n",
    "            min_val = torch.min(tensor)\n",
    "            max_val = torch.max(tensor)\n",
    "        else:\n",
    "            min_val = self.min_val\n",
    "            max_val = self.max_val\n",
    "        \n",
    "        normalized_tensor = (tensor - min_val) / (max_val - min_val)\n",
    "        return normalized_tensor\n",
    "\n",
    "\n",
    "# Mono To Color (for 3 channels)\n",
    "class MonoToColor(nn.Module):\n",
    "    def __init__(self, num_channels=3):\n",
    "        super(MonoToColor, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.repeat(self.num_channels, 1, 1)\n",
    "\n",
    "# Transform + appy all func\n",
    "transformation = transforms.Compose([\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=40),# higher the better but more complex. For talking we use 128, for sound effect, about 40.\n",
    "    torchaudio.transforms.AmplitudeToDB(stype='power', top_db=80),\n",
    "    MinMaxNormalize(),\n",
    "    MonoToColor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device #1 name: 갤럭시 S2 마이크\n",
      "Device #2 name: USB PnP Sound Device\n",
      "Device #4 name: MacBook Air 마이크\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import speech_recognition as sr\n",
    "import time\n",
    "\n",
    "def list_input_devices():\n",
    "    audio = pyaudio.PyAudio()\n",
    "    for i in range(audio.get_device_count()):\n",
    "        device_info = audio.get_device_info_by_index(i)\n",
    "        if device_info['maxInputChannels'] > 0:  # This is an input device\n",
    "            print(f\"Device #{i} name: {device_info['name']}\")\n",
    "\n",
    "def record_audio():\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=pyaudio.paInt16, channels=1, rate=16000, frames_per_buffer=1024, input=True , input_device_index=device_id)\n",
    "    frames = []\n",
    "    for i in range(0, int(16000 / 1024 * 3)):\n",
    "        data = stream.read(1024)\n",
    "        frames.append(data)\n",
    "    stream.close()\n",
    "    audio.terminate()  # close the PyAudio object\n",
    "    return b''.join(frames)\n",
    "def transcribe_audio(audio):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio_data = sr.AudioData(audio, 16000, 2)\n",
    "    try:\n",
    "        text = recognizer.recognize_sphinx(audio_data)\n",
    "        \n",
    "        return text\n",
    "    except:\n",
    "        return None\n",
    "def main(times):\n",
    "    for i in range(0, times):\n",
    "        audio = record_audio()\n",
    "        text = transcribe_audio(audio)\n",
    "        print(text)\n",
    "TIMES = 0\n",
    "if __name__ == \"__main__\":\n",
    "    main(TIMES)\n",
    "\n",
    "list_input_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOUND EFFECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cpu\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "import sounddevice as sd\n",
    "global count\n",
    "count = 0\n",
    "print(\"device : \",device)\n",
    "## print every labels\n",
    "def continuous_sound_prediction(model, device, transformation, sample_rate):\n",
    "\n",
    "    global count\n",
    "\n",
    "    count = count + 1\n",
    "\n",
    "    labels = [\n",
    "        \"nothing\", \"Car Horn\", \"Bell Ring\", \"Dog Bark\", \"nothing\", \n",
    "        \"nothing\", \"Glass Shatter\", \"nothing\", \"nothing\", \"Door Nock\", \n",
    "        \"nothing\", \"nothing\", \"Siren\", \"nothing\"\n",
    "    ]\n",
    "\n",
    "    duration = 2.0  # seconds\n",
    "    global buffer, buffer_index\n",
    "    buffer = np.zeros((int(duration * sample_rate),))\n",
    "    buffer_index = 0\n",
    "\n",
    "    # Start the InputStream to fill the buffer using the callback function\n",
    "    with sd.InputStream(callback=audio_callback, channels=1, samplerate=sample_rate):\n",
    "        sd.sleep(int(duration * 1000))\n",
    "\n",
    "    recording = buffer\n",
    "    \n",
    "    # Preprocessing\n",
    "    recording = torch.from_numpy(recording).float().transpose(0, 1)\n",
    "    if recording.shape[0] > 1:\n",
    "        recording = torch.mean(recording, dim=0, keepdim=True)\n",
    "    recording = nn.functional.pad(recording, (0, sample_rate - recording.shape[1]))\n",
    "    \n",
    "    # Transformation\n",
    "    recording = transformation(recording)\n",
    "    \n",
    "    # Prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        recording = recording.to(device)\n",
    "        outputs = model(recording.unsqueeze(0))\n",
    "        #probabilities = F.softmax(outputs, dim=1)\n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "    # Print results\n",
    "    probs = [f\"{label} {prob:.2%}\" for label, prob in zip(labels, probabilities[0])]\n",
    "    print(f\"{count} / {' / '.join(probs)}\")\n",
    "\n",
    "    max_prob, predicted_label_idx = probabilities[0].max(0)\n",
    "    max_prob_label = labels[predicted_label_idx]\n",
    "\n",
    "    if max_prob > 0.0:\n",
    "        if max_prob_label == 'nothing':\n",
    "            return '' , 0 , \"\"\n",
    "        return max_prob_label, max_prob, probabilities\n",
    "    else:\n",
    "        return \"\" , 0 , \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 결과 값 : \n",
      "RPi.GPIO import failed. No vibration\n",
      "pass vibration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.fonts: Populating font family aliases took 77 ms. Replace uses of missing font family \"AppleSystemUIFont\" with one that exists to avoid this cost. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored from cffi callback <function _StreamBase.__init__.<locals>.callback_ptr at 0x15aeb93a0>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/owo/anaconda3/envs/torchenv/lib/python3.11/site-packages/sounddevice.py\", line 846, in callback_ptr\n",
      "    return _wrap_callback(callback, data, frames, time, status)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/owo/anaconda3/envs/torchenv/lib/python3.11/site-packages/sounddevice.py\", line 2687, in _wrap_callback\n",
      "    callback(*args)\n",
      "  File \"/var/folders/sb/2gzn9_qx589_ft0jp8q6nbbc0000gn/T/ipykernel_64545/466994289.py\", line 20, in audio_callback\n",
      "ValueError: could not broadcast input array from shape (15,) into shape (0,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owo/anaconda3/envs/torchenv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from PyQt5.QtCore import QThread, pyqtSignal\n",
    "from PyQt5.QtGui import QMovie, QIcon\n",
    "from time import sleep\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QPushButton, QVBoxLayout, QWidget\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyaudio\n",
    "import torchaudio\n",
    "import sounddevice as sd\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "###### INIT ######\n",
    "p = pyaudio.PyAudio()\n",
    "sample_rate = SAMPLE_RATE\n",
    "target_sample_rate = SAMPLE_RATE\n",
    "mode = 1 ## 1 starts with sound effect, 0 starts with stt\n",
    "print(\" 결과 값 : \")\n",
    "\n",
    "\n",
    "# Sound Analysis class running on a separate thread\n",
    "class SoundAnalysis(QThread):\n",
    "    # Define a pyqtSignal with str type, which will be used to send the analysis results to the main thread\n",
    "    result_signal = pyqtSignal(str, float)  # Add a float type for the probability\n",
    "\n",
    "    def __init__(self, model, device, transformation, sample_rate):\n",
    "        QThread.__init__(self)\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.transformation = transformation\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "\n",
    "    def run(self):## Main code\n",
    "        count = 0\n",
    "        text_str = \"\"\n",
    "        while True:\n",
    "\n",
    "            if mode == True:\n",
    "                text_str = \"\" #empty the text strings\n",
    "\n",
    "                predicted_label, predicted_confidence, probabilities = continuous_sound_prediction(model, device, transformation, SAMPLE_RATE) \n",
    "                if mode == True:\n",
    "                    try:               \n",
    "                        self.result_signal.emit(predicted_label, predicted_confidence)\n",
    "                        #vibration()\n",
    "                    except:\n",
    "                        self.result_signal.emit(predicted_label, predicted_confidence)\n",
    "                    count = count + 1\n",
    "            if mode == False:\n",
    "\n",
    "                times = 2\n",
    "                for _ in range(0, times):\n",
    "                    audio = record_audio()\n",
    "                    text = transcribe_audio(audio)\n",
    "                    print(text)\n",
    "                    text_str += text + \" \"\n",
    "                    if mode == True: ## This is checking again if the button is pushed. If I dont add this, it will reset_label and show the text_str again before going to mode True\n",
    "                        break\n",
    "                    self.result_signal.emit(text_str,0)\n",
    "        \n",
    "    def reset_label(self):# Restting the labels when the button is pressed\n",
    "        self.result_signal.emit(\"켜는중\", 0)\n",
    "        \n",
    "class Ui_MainWindow(object):\n",
    "    def setupUi(self, MainWindow):\n",
    "        MainWindow.setObjectName(\"MainWindow\")\n",
    "        MainWindow.resize(640, 480)\n",
    "        \n",
    "        # 아이콘 파일 경로 설정 (ico 또는 이미지 파일 형식 지원)\n",
    "        icon_path = '../IMAGE/main.png'  # 아이콘 파일 경로를 지정합니다.\n",
    "        # 아이콘을 설정합니다.\n",
    "        MainWindow.setWindowIcon(QIcon(icon_path))  # QIcon 클래스를 사용하여 아이콘을 설정합니다.\n",
    "        \n",
    "        \n",
    "        MainWindow.setFocusPolicy(QtCore.Qt.NoFocus)\n",
    "        MainWindow.setStyleSheet(\"background: white;\")\n",
    "        self.received_text = \"\"\n",
    "        self.centralwidget = QtWidgets.QWidget(MainWindow)\n",
    "        self.centralwidget.setObjectName(\"centralwidget\")\n",
    "        \n",
    "        # Create a QScrollArea\n",
    "        self.scrollArea = QtWidgets.QScrollArea(self.centralwidget)\n",
    "        self.scrollArea.setGeometry(QtCore.QRect(10, 300, 611, 121))\n",
    "        self.scrollArea.setWidgetResizable(True)\n",
    "        self.scrollArea.setObjectName(\"scrollArea\")\n",
    "\n",
    "        # Create the label inside the QScrollArea\n",
    "        self.label = QtWidgets.QLabel(self.scrollArea)\n",
    "        self.label.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.label.setStyleSheet(\"background-color: white;\")\n",
    "\n",
    "        self.label.setObjectName(\"text_label\")\n",
    "        self.label.setWordWrap(True)\n",
    "        self.scrollArea.setWidget(self.label)\n",
    "\n",
    "        self.label_2 = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.label_2.setGeometry(QtCore.QRect(10, 10, 370, 261))\n",
    "        self.label_2.setStyleSheet(\"background: transparent;\")\n",
    "\n",
    "        \n",
    "        self.label_2.setText(\"\")\n",
    "        self.label_2.setObjectName(\"imgae_image\")\n",
    "        \n",
    "    \n",
    "        \n",
    "        self.pushButton = QtWidgets.QPushButton(self.centralwidget)\n",
    "        self.pushButton.setGeometry(QtCore.QRect(420, 50, 171, 111))\n",
    "        font = QtGui.QFont()\n",
    "        font.setFamily(\"Eras Demi ITC\") #폰트 이름\n",
    "        font.setPointSize(30) #글씨 크기\n",
    "        self.pushButton.setFont(font)\n",
    "        self.pushButton.setObjectName(\"pushButton\")\n",
    "        self.pushButton.setText(\"Switch\")\n",
    "        self.pushButton.setStyleSheet(\"QPushButton {\\n\"\n",
    "\"background: white;\\n\"\n",
    "\"    border-radius: 10px; /* 원하는 모서리 둥글기 정도를 설정 */\\n\"\n",
    "\"    border: 2px solid gray; /* 버튼 테두리 스타일 및 색상 설정 */\\n\"\n",
    "\"}\\n\"\n",
    "\"\")\n",
    "\n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "\n",
    "        #english_text_label\n",
    "        self.new_label = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.new_label.setGeometry(QtCore.QRect(40, 200, 561, 201))\n",
    "        self.label.setStyleSheet(\"QLabel {\\n\"\n",
    "\"    border: 2px black; /* 테두리 스타일 및 색상 설정 (선택 사항) */\\n\"\n",
    "\"    border-radius: 10px; /* 원하는 모서리 둥글기 정도를 설정 */\\n\"\n",
    "\"    background-color: white; /* 배경색 설정 (선택 사항) */\\n\"\n",
    "\"    padding: 10px; /* 라벨 내부 여백 설정 (선택 사항) */\\n\"\n",
    "\"}\")\n",
    "        self.new_label.setText(\"\")\n",
    "        self.new_label.setAlignment(QtCore.Qt.AlignCenter)  # 텍스트 중앙 정렬\n",
    "        self.new_label.setObjectName(\"english_text_label\")\n",
    "        self.new_label.hide()  # Hide the new label initially\n",
    "        \n",
    "        #english_image_label\n",
    "        self.new_label_2 = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.new_label_2.setGeometry(QtCore.QRect(90, 70, 191, 161))\n",
    "        self.new_label_2.setStyleSheet(\"background: transparent;\")\n",
    "        self.new_label_2.setPixmap(QtGui.QPixmap(\"english_image.png\"))\n",
    "        self.new_label_2.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.new_label_2.setObjectName(\"english_image_label\")\n",
    "        self.new_label_2.hide()\n",
    "\n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "        self.menubar = QtWidgets.QMenuBar(MainWindow)\n",
    "        self.menubar.setGeometry(QtCore.QRect(0, 0, 800, 29))\n",
    "        self.menubar.setObjectName(\"menubar\")\n",
    "        MainWindow.setMenuBar(self.menubar)\n",
    "        self.statusbar = QtWidgets.QStatusBar(MainWindow)\n",
    "        self.statusbar.setObjectName(\"statusbar\")\n",
    "        MainWindow.setStatusBar(self.statusbar)\n",
    "\n",
    "        self.retranslateUi(MainWindow)\n",
    "        QtCore.QMetaObject.connectSlotsByName(MainWindow)\n",
    "\n",
    "        self.pushButton.clicked.connect(self.onPushButtonClicked)\n",
    "\n",
    "        # Initialize SoundAnalysis and connect the result_signal with the updateLabel function\n",
    "        self.sound_analysis = SoundAnalysis(model, device, transformation, SAMPLE_RATE)\n",
    "        self.sound_analysis.result_signal.connect(self.updateLabel)\n",
    "        self.sound_analysis.result_signal.connect(self.updateLabel2)\n",
    "        self.sound_analysis.start()  # Start the sound analysis thread\n",
    "        \n",
    "        self.is_new_labels_visible = False\n",
    "\n",
    "        \n",
    "\n",
    "    def onPushButtonClicked(self): ######BUTTON#######\n",
    "        global mode\n",
    "        mode = not mode\n",
    "        if mode == 1:\n",
    "            self.new_label_2.hide()  # Hide the new label initially\n",
    "        else:\n",
    "            self.new_label_2.show()\n",
    "        self.sound_analysis.reset_label()#reset the screen (its connected to the sound analysis class)\n",
    "        print(\"mode now :  \",mode)\n",
    "\n",
    "    def updateLabel(self, predicted_label, predicted_confidence):\n",
    "        #print(\"Received signal\")  # Print message when signal is received\n",
    "        if predicted_confidence == 0:\n",
    "            self.label.setText(f\"{predicted_label}\")\n",
    "        else:\n",
    "            self.label.setText(f\"{predicted_label}  {predicted_confidence*100:.2f}%\")\n",
    "        #print(predicted_label)\n",
    "        \n",
    "        # After updating the text, ensure the QScrollArea scrolls to the bottom\n",
    "        self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().maximum())\n",
    "\n",
    "        \n",
    "        \n",
    "    def updateLabel2(self, predicted_label):\n",
    "        relative_image_folder_path = \"../IMAGE/GIF\" #\\ only works for windows\n",
    "        image_folder_path= os.path.join(current_path, relative_image_folder_path)\n",
    "        full_file_name = os.path.join(image_folder_path, f\"{predicted_label}.gif\")\n",
    "        self.movie = QMovie(full_file_name)\n",
    "        self.label_2.setMovie(self.movie)\n",
    "        self.movie.start()\n",
    "        #print(predicted_label)\n",
    "\n",
    "\n",
    "    def retranslateUi(self, MainWindow):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        MainWindow.setWindowTitle(_translate(\"MainWindow\", \"Sound\"))\n",
    "        self.label.setFont(QtGui.QFont(\"AppleSystemUIFont\",20))\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "       \n",
    "        \n",
    "try:\n",
    "    import RPi.GPIO as GPIO\n",
    "    print(\"RPi.GPIO loaded successfully\")\n",
    "    import threading\n",
    "    print(\"threading loaded successfully\")\n",
    "\n",
    "    class VibrationController:\n",
    "        def __init__(self):\n",
    "            # 핀 번호 설정\n",
    "            self.red_button_pin = 5\n",
    "            self.yellow_button_pin = 6\n",
    "            self.green_button_pin = 13\n",
    "            self.vibration_motor_pin = 12\n",
    "            \n",
    "            # 진동 세기 초기화\n",
    "            self.vibration_intensity_temp = 100\n",
    "            self.vibration_intensity = 0\n",
    "            \n",
    "            # 이전 스위치 상태 초기화\n",
    "            self.prev_red_button_state = GPIO.HIGH\n",
    "            self.prev_yellow_button_state = GPIO.HIGH\n",
    "            self.prev_green_button_state = GPIO.HIGH\n",
    "            \n",
    "            self.debounce_time = 0.2\n",
    "            \n",
    "            # 진동 상태를 저장하는 변수\n",
    "            self.vibration_on = False\n",
    "            \n",
    "            # GPIO 초기화\n",
    "            GPIO.setmode(GPIO.BCM)\n",
    "            GPIO.setup(self.red_button_pin, GPIO.IN, pull_up_down=GPIO.PUD_UP)\n",
    "            GPIO.setup(self.yellow_button_pin, GPIO.IN, pull_up_down=GPIO.PUD_UP)\n",
    "            GPIO.setup(self.green_button_pin, GPIO.IN, pull_up_down=GPIO.PUD_UP)\n",
    "            GPIO.setup(self.vibration_motor_pin, GPIO.OUT)\n",
    "            \n",
    "            # PWM 설정\n",
    "            self.pwm_frequency = 1000\n",
    "            self.pwm = GPIO.PWM(self.vibration_motor_pin, self.pwm_frequency)\n",
    "            self.pwm.start(self.vibration_intensity)\n",
    "        \n",
    "        def display_vibration_intensity(self):\n",
    "            print(f\"진동 세기: {self.vibration_intensity}\")\n",
    "        \n",
    "        def adjust_vibration_intensity(self, button_pin):\n",
    "            if button_pin == self.red_button_pin:\n",
    "                self.vibration_intensity = self.vibration_intensity_temp\n",
    "            elif button_pin == self.yellow_button_pin:\n",
    "                self.vibration_intensity = max(self.vibration_intensity - 10, 0)\n",
    "            elif button_pin == self.green_button_pin:\n",
    "                self.vibration_intensity = min(self.vibration_intensity + 10, 100)\n",
    "            \n",
    "            self.pwm.ChangeDutyCycle(self.vibration_intensity)\n",
    "            self.display_vibration_intensity()\n",
    "        \n",
    "        def run(self):\n",
    "            try:\n",
    "                while True:\n",
    "                    red_button_state = GPIO.input(self.red_button_pin)\n",
    "                    yellow_button_state = GPIO.input(self.yellow_button_pin)\n",
    "                    green_button_state = GPIO.input(self.green_button_pin)\n",
    "            \n",
    "                    if red_button_state != self.prev_red_button_state:\n",
    "                        time.sleep(self.debounce_time)\n",
    "                        if red_button_state != GPIO.input(self.red_button_pin):\n",
    "                            \n",
    "                            if not self.vibration_on:\n",
    "                                self.vibration_on = True\n",
    "                                self.adjust_vibration_intensity(self.red_button_pin)\n",
    "                            else:\n",
    "                                self.vibration_intensity_temp = self.vibration_intensity\n",
    "                                self.vibration_intensity = 0\n",
    "                                self.pwm.ChangeDutyCycle(self.vibration_intensity)\n",
    "                                self.display_vibration_intensity()\n",
    "                                self.vibration_on = False\n",
    "            \n",
    "                        self.prev_red_button_state = red_button_state\n",
    "            \n",
    "                    if yellow_button_state != self.prev_yellow_button_state:\n",
    "                        time.sleep(self.debounce_time)\n",
    "                        if yellow_button_state != GPIO.input(self.yellow_button_pin):\n",
    "                            self.adjust_vibration_intensity(self.yellow_button_pin)\n",
    "                        self.prev_yellow_button_state = yellow_button_state\n",
    "            \n",
    "                    if green_button_state != self.prev_green_button_state:\n",
    "                        time.sleep(self.debounce_time)\n",
    "                        if green_button_state != GPIO.input(self.green_button_pin):\n",
    "                            self.adjust_vibration_intensity(self.green_button_pin)\n",
    "                        self.prev_green_button_state = green_button_state\n",
    "            \n",
    "                    time.sleep(0.01)  \n",
    "            \n",
    "            except KeyboardInterrupt:\n",
    "                self.pwm.stop()\n",
    "                GPIO.cleanup()\n",
    "except:\n",
    "    print(\"RPi.GPIO import failed. No vibration\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    MainWindow = QtWidgets.QMainWindow()\n",
    "    try:\n",
    "        vibration_controller = VibrationController()\n",
    "        vibration_thread = threading.Thread(target=vibration_controller.run)\n",
    "        vibration_thread.start()\n",
    "    except:\n",
    "        print(\"pass vibration\")\n",
    "    ui = Ui_MainWindow()\n",
    "    ui.setupUi(MainWindow)\n",
    "    MainWindow.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가능한 폰트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtGui import QFontDatabase\n",
    "\n",
    "print(QFontDatabase().families())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
